import streamlit as st
import FinanceDataReader as fdr
import pandas as pd
import numpy as np
import time
from datetime import datetime, timedelta
import plotly.graph_objects as go
import openai
from typing import Dict, Any

from sklearn.preprocessing import MinMaxScaler, PolynomialFeatures
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import (
    r2_score,
    mean_absolute_error,
    mean_squared_error,
    accuracy_score,
    precision_score,
    recall_score,
    f1_score,
    roc_curve,
    auc
)

# ìƒìˆ˜ ì •ì˜
US_STOCKS = {
    'AAPL': 'Apple Inc.',
    'MSFT': 'Microsoft Corporation',
    'GOOGL': 'Alphabet Inc.',
    'AMZN': 'Amazon.com Inc.',
    'META': 'Meta Platforms Inc.',
    'TSLA': 'Tesla Inc.',
    'NVDA': 'NVIDIA Corporation'
}

# TensorFlow ê°€ìš©ì„± í™•ì¸
try:
    import tensorflow as tf
    from tensorflow.keras.models import Sequential
    from tensorflow.keras.layers import LSTM, Dense, Dropout
    from tensorflow.keras.optimizers import Adam
    from tensorflow.keras.callbacks import EarlyStopping
    TENSORFLOW_AVAILABLE = True
except ImportError:
    TENSORFLOW_AVAILABLE = False
    st.warning("TensorFlowë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. LSTM ëª¨ë¸ì€ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

from xgboost import XGBClassifier
from lightgbm import LGBMClassifier

# LightGBM ê°€ìš©ì„± í™•ì¸
try:
    import lightgbm as lgb
    LIGHTGBM_AVAILABLE = True
except ImportError:
    LIGHTGBM_AVAILABLE = False
    st.warning("LightGBMì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì„¤ì¹˜í•˜ë ¤ë©´: pip install lightgbm")

# XGBoost ê°€ìš©ì„± í™•ì¸
try:
    XGBOOST_AVAILABLE = True
except ImportError:
    XGBOOST_AVAILABLE = False
    st.warning("XGBoostë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì„¤ì¹˜í•˜ë ¤ë©´: pip install xgboost")

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="Financial Machine Learning App", layout="wide")
st.title("Financial Machine Learning Analysis")

# ëª¨ë¸ ì„¤ëª… ì„¹ì…˜
with st.expander("ğŸ“š ëª¨ë¸ ì„¤ëª… ë° íŒŒë¼ë¯¸í„° ê°€ì´ë“œ", expanded=True):
    st.markdown("""
    ### ğŸ¤– ëª¨ë¸ ì¢…ë¥˜ë³„ íŠ¹ì§•
    
    #### 1. Random Forest
    - **íŠ¹ì§•**: ì—¬ëŸ¬ ê°œì˜ ì˜ì‚¬ê²°ì • íŠ¸ë¦¬ë¥¼ ìƒì„±í•˜ì—¬ ì•™ìƒë¸”í•˜ëŠ” ëª¨ë¸
    - **ì¥ì **: ê³¼ì í•©ì— ê°•í•˜ê³ , íŠ¹ì„± ì¤‘ìš”ë„ë¥¼ íŒŒì•…í•  ìˆ˜ ìˆìŒ
    - **ë‹¨ì **: ëª¨ë¸ì´ ë³µì¡í•˜ê³  í•™ìŠµ/ì˜ˆì¸¡ ì‹œê°„ì´ ê¹€
    
    #### 2. ì„ í˜• íšŒê·€
    - **íŠ¹ì§•**: ì…ë ¥ ë³€ìˆ˜ì™€ ì¶œë ¥ ë³€ìˆ˜ ê°„ì˜ ì„ í˜• ê´€ê³„ë¥¼ ëª¨ë¸ë§
    - **ì¥ì **: í•´ì„ì´ ì‰½ê³  í•™ìŠµì´ ë¹ ë¦„
    - **ë‹¨ì **: ë¹„ì„ í˜• ê´€ê³„ë¥¼ í¬ì°©í•˜ê¸° ì–´ë ¤ì›€
    
    #### 3. LSTM
    - **íŠ¹ì§•**: ì‹œê³„ì—´ ë°ì´í„° ë¶„ì„ì— íŠ¹í™”ëœ ë”¥ëŸ¬ë‹ ëª¨ë¸
    - **ì¥ì **: ì¥ê¸° ì˜ì¡´ì„±ì„ ì˜ í¬ì°©í•˜ê³  ë³µì¡í•œ íŒ¨í„´ í•™ìŠµ ê°€ëŠ¥
    - **ë‹¨ì **: ë§ì€ ë°ì´í„°ì™€ ê³„ì‚° ìì›ì´ í•„ìš”
    
    ### ğŸ“Š íŒŒë¼ë¯¸í„° ì„¤ëª…
    
    #### Random Forest íŒŒë¼ë¯¸í„°
    - **íŠ¸ë¦¬ ê°œìˆ˜**: ìƒì„±í•  ì˜ì‚¬ê²°ì • íŠ¸ë¦¬ì˜ ìˆ˜ (ë§ì„ìˆ˜ë¡ ì•ˆì •ì ì´ë‚˜ ëŠë ¤ì§)
    - **ìµœëŒ€ ê¹Šì´**: ê° íŠ¸ë¦¬ì˜ ìµœëŒ€ ê¹Šì´ (ê¹Šì„ìˆ˜ë¡ ê³¼ì í•© ìœ„í—˜)
    
    #### ì„ í˜• íšŒê·€ íŒŒë¼ë¯¸í„°
    - **íšŒê·€ ìœ í˜•**: 
        - Linear: ê¸°ë³¸ ì„ í˜• íšŒê·€
        - Ridge: L2 ê·œì œ ì ìš©
        - Lasso: L1 ê·œì œ ì ìš©
    - **ì•ŒíŒŒ**: ê·œì œ ê°•ë„ (ë†’ì„ìˆ˜ë¡ ëª¨ë¸ì´ ë‹¨ìˆœí•´ì§)
    
    #### LSTM íŒŒë¼ë¯¸í„°
    - **ì‹œí€€ìŠ¤ ê¸¸ì´**: ì˜ˆì¸¡ì— ì‚¬ìš©í•  ê³¼ê±° ë°ì´í„° ê¸°ê°„
    - **LSTM ìœ ë‹› ìˆ˜**: ëª¨ë¸ì˜ ë³µì¡ë„ ê²°ì •
    - **Dropout ë¹„ìœ¨**: ê³¼ì í•© ë°©ì§€ë¥¼ ìœ„í•œ ë¹„ìœ¨
    - **í•™ìŠµë¥ **: ëª¨ë¸ í•™ìŠµ ì†ë„ ì¡°ì ˆ
    
    ### ğŸ“ˆ ê²°ê³¼ í•´ì„ ê°€ì´ë“œ
    
    #### ì„±ëŠ¥ ì§€í‘œ
    - **MSE (Mean Squared Error)**: ì˜ˆì¸¡ê°’ê³¼ ì‹¤ì œê°’ì˜ ì°¨ì´ë¥¼ ì œê³±í•œ í‰ê· 
        - ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ
        - ì‹¤ì œ ì£¼ê°€ ë‹¨ìœ„ì˜ ì œê³±
    - **RÂ² Score**: ëª¨ë¸ì´ ì„¤ëª…í•˜ëŠ” ë¶„ì‚°ì˜ ë¹„ìœ¨
        - 1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ì¢‹ìŒ
        - 0~1 ì‚¬ì´ì˜ ê°’
    
    #### ì‹œê°í™”
    - **íŠ¹ì„± ì¤‘ìš”ë„**: ê° ì…ë ¥ ë³€ìˆ˜ê°€ ì˜ˆì¸¡ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ë ¥
    - **í•™ìŠµ ê³¡ì„ **: ëª¨ë¸ì˜ í•™ìŠµ ì§„í–‰ ìƒí™©
    - **ì˜ˆì¸¡ ê²°ê³¼**: ì‹¤ì œ ê°€ê²©ê³¼ ì˜ˆì¸¡ ê°€ê²© ë¹„êµ
    """)

# ì‚¬ì´ë“œë°” íŒŒë¼ë¯¸í„° ì„¤ì •
st.sidebar.header("ëª¨ë¸ íŒŒë¼ë¯¸í„° ì„¤ì •")

ticker = st.sidebar.text_input("ì£¼ì‹ ì‹¬ë³¼ ì…ë ¥", "AAPL")
col1, col2 = st.sidebar.columns(2)
with col1:
    start_date = st.date_input("ì‹œì‘ì¼", datetime.now() - timedelta(days=365*3))
with col2:
    end_date = st.date_input("ì¢…ë£Œì¼", datetime.now())

model_type = st.sidebar.selectbox(
    "ëª¨ë¸ ì„ íƒ",
    ["Random Forest", "ì„ í˜• íšŒê·€", "LSTM", "XGBoost", "LightGBM"]
)

enable_auto_tuning = st.sidebar.checkbox("í•˜ì´í¼íŒŒë¼ë¯¸í„° ìë™ íŠœë‹", value=False)

if model_type == "Random Forest":
    st.sidebar.subheader("Random Forest íŒŒë¼ë¯¸í„°")
    n_estimators = st.sidebar.slider(
        "íŠ¸ë¦¬ ê°œìˆ˜ (n_estimators)", 
        min_value=10, 
        max_value=500, 
        value=100,
        help="ë” ë§ì€ íŠ¸ë¦¬ë¥¼ ì‚¬ìš©í•˜ë©´ ëª¨ë¸ì˜ ì•ˆì •ì„±ì´ í–¥ìƒë˜ì§€ë§Œ í•™ìŠµ ì‹œê°„ì´ ì¦ê°€í•©ë‹ˆë‹¤."
    )
    
    max_depth = st.sidebar.slider(
        "ìµœëŒ€ ê¹Šì´ (max_depth)", 
        min_value=1, 
        max_value=50, 
        value=10,
        help="íŠ¸ë¦¬ì˜ ìµœëŒ€ ê¹Šì´ë¥¼ ì œí•œí•˜ì—¬ ê³¼ì í•©ì„ ë°©ì§€í•©ë‹ˆë‹¤."
    )

elif model_type == "ì„ í˜• íšŒê·€":
    st.sidebar.subheader("ì„ í˜• íšŒê·€ íŒŒë¼ë¯¸í„°")
    regression_type = st.sidebar.selectbox(
        "íšŒê·€ ëª¨ë¸ ìœ í˜•",
        ["Linear", "Ridge", "Lasso"]
    )
    
    if regression_type in ["Ridge", "Lasso"]:
        alpha = st.sidebar.slider(
            "ì•ŒíŒŒ (ê·œì œ ê°•ë„)", 
            min_value=0.0, 
            max_value=10.0, 
            value=1.0,
            help="ë†’ì€ ê°’ì€ ë” ê°•í•œ ê·œì œë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤."
        )

elif model_type == "LSTM":
    st.sidebar.subheader("LSTM íŒŒë¼ë¯¸í„°")
    sequence_length = st.sidebar.slider(
        "ì‹œí€€ìŠ¤ ê¸¸ì´", 
        min_value=5, 
        max_value=60, 
        value=30,
        help="ì˜ˆì¸¡ì— ì‚¬ìš©í•  ê³¼ê±° ë°ì´í„°ì˜ ê¸°ê°„"
    )
    
    lstm_units = st.sidebar.slider(
        "LSTM ìœ ë‹› ìˆ˜", 
        min_value=32, 
        max_value=256, 
        value=128,
        help="ëª¨ë¸ì˜ ë³µì¡ë„ë¥¼ ê²°ì •í•©ë‹ˆë‹¤."
    )
    
    dropout_rate = st.sidebar.slider(
        "Dropout ë¹„ìœ¨", 
        min_value=0.0, 
        max_value=0.5, 
        value=0.2,
        help="ê³¼ì í•© ë°©ì§€ë¥¼ ìœ„í•œ dropout ë¹„ìœ¨"
    )
    
    learning_rate = st.sidebar.slider(
        "í•™ìŠµë¥ ", 
        min_value=0.0001, 
        max_value=0.01, 
        value=0.001,
        format="%.4f",
        help="ëª¨ë¸ì˜ í•™ìŠµ ì†ë„ë¥¼ ì¡°ì ˆí•©ë‹ˆë‹¤."
    )

test_size = st.sidebar.slider(
    "í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¹„ìœ¨", 
    min_value=0.1, 
    max_value=0.4, 
    value=0.2,
    help="ì „ì²´ ë°ì´í„° ì¤‘ í…ŒìŠ¤íŠ¸ì— ì‚¬ìš©í•  ë¹„ìœ¨ì„ ì„¤ì •í•©ë‹ˆë‹¤."
)

@st.cache_data(ttl=3600)
def get_stock_data(ticker, start, end):
    """ì£¼ì‹ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜"""
    try:
        if ticker.upper() in US_STOCKS:
            try:
                df = fdr.DataReader(ticker, start, end)
                if df.empty:
                    st.error(f"{ticker}ì— ëŒ€í•œ ì£¼ê°€ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                    if ticker.upper() in US_STOCKS:
                        st.info(
                            f"'{US_STOCKS[ticker.upper()]}' "
                            f"({ticker.upper()})ì˜ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                        )
                    else:
                        st.info("ë¯¸êµ­ ì£¼ì‹ ì‹¬ë³¼ì„ í™•ì¸í•˜ê³  ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
                    return None

                stock_name = US_STOCKS.get(ticker.upper(), ticker.upper())
                st.success(
                    f"ë¯¸êµ­ ì£¼ì‹ '{stock_name}' ({ticker.upper()}) "
                    "ë°ì´í„°ë¥¼ ì„±ê³µì ìœ¼ë¡œ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤."
                )

            except Exception as us_error:
                st.error(
                    f"ë¯¸êµ­ ì£¼ì‹ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ”ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {str(us_error)}"
                )
                return None
        else:
            try:
                # KRX ë°ì´í„° ê°€ì ¸ì˜¤ê¸° (ìµœëŒ€ 3ë²ˆ ì¬ì‹œë„)
                max_retries = 3
                retry_count = 0
                stock_info = None
                
                while retry_count < max_retries:
                    try:
                        stock_info = fdr.StockListing('KRX')
                        break
                    except Exception as retry_error:
                        retry_count += 1
                        if retry_count == max_retries:
                            st.error("KRX ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ”ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                            st.info(f"ì˜¤ë¥˜ ë‚´ìš©: {str(retry_error)}")
                            return None
                        time.sleep(1)
                
                if stock_info is None or stock_info.empty:
                    st.error("KRX ì¢…ëª© ì •ë³´ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
                    st.info("ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
                    return None
                
                if 'Symbol' not in stock_info.columns or 'Name' not in stock_info.columns:
                    available_columns = ', '.join(stock_info.columns)
                    st.error("KRX ë°ì´í„°ì—ì„œ í•„ìˆ˜ ì •ë³´(Symbol/Name)ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    st.info(f"ì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ëŸ¼: {available_columns}")
                    return None
                
                # ì¢…ëª© ì½”ë“œë¡œ ê²€ìƒ‰
                matching_stocks = stock_info[stock_info['Symbol'] == ticker]
                if matching_stocks.empty:
                    # ì¢…ëª©ëª…ìœ¼ë¡œ ê²€ìƒ‰ ì‹œë„
                    name_match = stock_info[stock_info['Name'].str.contains(ticker, case=False, na=False)]
                    if not name_match.empty:
                        st.warning(f"ì…ë ¥í•˜ì‹  '{ticker}'ëŠ” ì¢…ëª©ëª…ì…ë‹ˆë‹¤. ë‹¤ìŒ ì¢…ëª©ë“¤ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤:")
                        for _, row in name_match.iterrows():
                            st.write(f"- {row['Name']}: {row['Symbol']}")
                        return None
                    else:
                        st.error(f"'{ticker}'ì— í•´ë‹¹í•˜ëŠ” í•œêµ­ ì£¼ì‹ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                        st.info("ì˜¬ë°”ë¥¸ ì¢…ëª© ì½”ë“œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”. (ì˜ˆ: ì‚¼ì„±ì „ì - 005930)")
                        return None
                
                stock_name = matching_stocks['Name'].iloc[0]
                
                # ì£¼ê°€ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
                df = fdr.DataReader(ticker, start, end)
                if df is None or df.empty:
                    st.error(f"{stock_name} ({ticker})ì— ëŒ€í•œ ì£¼ê°€ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                    st.info("ì¢…ëª© ì½”ë“œì™€ ë‚ ì§œë¥¼ í™•ì¸í•˜ê³  ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
                    return None
                
                st.success(f"í•œêµ­ ì£¼ì‹ '{stock_name}' ({ticker}) ë°ì´í„°ë¥¼ ì„±ê³µì ìœ¼ë¡œ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤.")
                
            except Exception as kr_error:
                st.error(f"í•œêµ­ ì£¼ì‹ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ”ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {str(kr_error)}")
                st.info("ì¢…ëª© ì½”ë“œë¥¼ í™•ì¸í•˜ê³  ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
                return None
        
        # í•„ìš”í•œ ì»¬ëŸ¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
        required_columns = ['Open', 'High', 'Low', 'Close', 'Volume']
        missing_columns = [col for col in required_columns if col not in df.columns]
        if missing_columns:
            st.error(f"í•„ìˆ˜ ë°ì´í„°ê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤: {', '.join(missing_columns)}")
            return None
        
        # í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒí•˜ê³  ê²°ì¸¡ì¹˜ ì²˜ë¦¬
        df = df[required_columns].fillna(method='ffill').fillna(method='bfill')
        return df
        
    except Exception as e:
        st.error(f"ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
        st.info("ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
        return None

def validate_parameters(model_type, **params):
    try:
        if model_type == "Random Forest":
            if params.get('n_estimators', 0) < 10:
                st.warning("íŠ¸ë¦¬ ê°œìˆ˜ê°€ ë„ˆë¬´ ì ìŠµë‹ˆë‹¤. ìµœì†Œ 10ê°œ ì´ìƒì„ ê¶Œì¥í•©ë‹ˆë‹¤.")
            if params.get('max_depth', 0) > 30:
                st.warning("íŠ¸ë¦¬ ê¹Šì´ê°€ ê¹ŠìŠµë‹ˆë‹¤. ê³¼ì í•©ì˜ ìœ„í—˜ì´ ìˆìŠµë‹ˆë‹¤.")
        elif model_type == "LSTM":
            if params.get('sequence_length', 0) < 10:
                st.warning("ì‹œí€€ìŠ¤ ê¸¸ì´ê°€ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤. ì˜ˆì¸¡ ì •í™•ë„ê°€ ë‚®ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            if params.get('dropout_rate', 0) > 0.5:
                st.warning("Dropout ë¹„ìœ¨ì´ ë†’ìŠµë‹ˆë‹¤. í•™ìŠµì´ ë¶ˆì•ˆì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        return True
    except Exception as e:
        st.error(f"íŒŒë¼ë¯¸í„° ê²€ì¦ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return False

def prepare_lstm_data(data, sequence_length):
    scaler = MinMaxScaler()
    scaled_data = scaler.fit_transform(data[['Close']])
    
    X, y = [], []
    for i in range(len(scaled_data) - sequence_length):
        X.append(scaled_data[i:(i + sequence_length), 0])
        y.append(scaled_data[i + sequence_length, 0])
    
    X = np.array(X)
    y = np.array(y)
    X = np.reshape(X, (X.shape[0], X.shape[1], 1))
    
    return X, y, scaler

def get_model_and_params(model_type):
    if model_type == "Random Forest":
        model = RandomForestClassifier(random_state=42)
        param_grid = {
            'n_estimators': [50, 100, 200],
            'max_depth': [5, 10, 15],
            'min_samples_split': [2, 5, 10]
        }
    elif model_type == "XGBoost":
        model = XGBClassifier(random_state=42)
        param_grid = {
            'n_estimators': [50, 100, 200],
            'max_depth': [3, 5, 7],
            'learning_rate': [0.01, 0.1, 0.3]
        }
    elif model_type == "LightGBM":
        model = LGBMClassifier(random_state=42)
        param_grid = {
            'n_estimators': [50, 100, 200],
            'num_leaves': [31, 62, 127],
            'learning_rate': [0.01, 0.1, 0.3]
        }
    else:
        return None, None
    
    return model, param_grid

def auto_tune_model(model, param_grid, X_train, y_train):
    with st.spinner("í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ì¤‘..."):
        grid_search = GridSearchCV(
            estimator=model,
            param_grid=param_grid,
            cv=5,
            n_jobs=-1,
            scoring='neg_mean_squared_error'
        )
        grid_search.fit(X_train, y_train)
        
        st.success("ìµœì ì˜ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤!")
        st.write("ìµœì  íŒŒë¼ë¯¸í„°:", grid_search.best_params_)
        st.write("ìµœì  ì ìˆ˜:", -grid_search.best_score_)
        
        return grid_search.best_estimator_

def plot_feature_importance(self):
    try:
        st.write("### ëª¨ë¸ë³„ íŠ¹ì„± ì¤‘ìš”ë„ ë¶„ì„")
        for name, model in self.models.items():
            try:
                if name == 'Linear Regression':
                    # íŠ¹ì„± ì´ë¦„ì„ ë¬¸ìì—´ë¡œ ì ì ˆíˆ ë³€í™˜
                    raw_feature_names = self.poly_features.get_feature_names_out(self.X_train.columns)
                    feature_names = []
                    for feat in raw_feature_names:
                        feat_str = str(feat)
                        if isinstance(feat, (tuple, list)):
                            feat_str = ' * '.join(map(str, feat))
                        feature_names.append(feat_str)
                    importance = np.abs(model.coef_)
                elif name == 'LSTM':
                    continue  # LSTMì€ íŠ¹ì„± ì¤‘ìš”ë„ë¥¼ ì œê³µí•˜ì§€ ì•ŠìŒ
                elif name in ['Random Forest', 'XGBoost', 'LightGBM']:
                    if not hasattr(model, 'feature_importances_'):
                        continue
                    feature_names = [str(col) for col in self.X_train.columns]
                    importance = model.feature_importances_
                else:
                    continue
                
                # ë°ì´í„°í”„ë ˆì„ ìƒì„± ë° ì •ë ¬
                importance_df = pd.DataFrame({
                    'Feature': feature_names,
                    'Importance': importance
                })
                importance_df = importance_df.sort_values('Importance', ascending=False).head(15)
                
                # Plotly ê·¸ë˜í”„ ìƒì„±
                fig = go.Figure()
                fig.add_trace(
                    go.Bar(
                        x=importance_df['Importance'],
                        y=importance_df['Feature'],
                        orientation='h',
                        marker=dict(
                            color=importance_df['Importance'],
                            colorscale='YlOrRd'
                        )
                    )
                )
                
                fig.update_layout(
                    title=f'{name} ëª¨ë¸ì˜ íŠ¹ì„± ì¤‘ìš”ë„',
                    xaxis_title='ì¤‘ìš”ë„',
                    yaxis_title='íŠ¹ì„±',
                    height=600,
                    yaxis=dict(autorange="reversed")
                )
                st.plotly_chart(fig)
                
                # ìƒì„¸ ë°ì´í„° í‘œì‹œ
                st.write(f"#### {name} ëª¨ë¸ì˜ íŠ¹ì„± ì¤‘ìš”ë„ ìƒì„¸")
                st.dataframe(
                    importance_df.style
                    .background_gradient(cmap='YlOrRd', subset=['Importance'])
                )
                
            except Exception as model_error:
                st.warning(f"{name} ëª¨ë¸ì˜ íŠ¹ì„± ì¤‘ìš”ë„ë¥¼ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {str(model_error)}")
                continue
            
    except Exception as e:
        st.error(f"íŠ¹ì„± ì¤‘ìš”ë„ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

def plot_learning_curves(history):
    if history is not None and hasattr(history, 'history'):
        fig = go.Figure()
        fig.add_trace(
            go.Scatter(
                y=history.history['loss'],
                name='Train Loss'
            )
        )
        if 'val_loss' in history.history:
            fig.add_trace(
                go.Scatter(
                    y=history.history['val_loss'],
                    name='Validation Loss'
                )
            )
        fig.update_layout(
            title='í•™ìŠµ ê³¡ì„ ',
            xaxis_title='Epoch',
            yaxis_title='Loss'
        )
        st.plotly_chart(fig)

def evaluate_model(model, X_test, y_test, scaler=None):
    start_time = time.time()
    y_pred = model.predict(X_test)
    inference_time = time.time() - start_time
    
    metrics = {
        'MAE': mean_absolute_error(y_test, y_pred),
        'MSE': mean_squared_error(y_test, y_pred),
        'RMSE': np.sqrt(mean_squared_error(y_test, y_pred)),
        'R2 Score': r2_score(y_test, y_pred),
        'ì¶”ë¡  ì‹œê°„': f"{inference_time:.4f}ì´ˆ"
    }
    
    st.subheader("ğŸ“Š ëª¨ë¸ ì„±ëŠ¥ í‰ê°€")
    metrics_df = pd.DataFrame([metrics]).T
    metrics_df.columns = ['ê°’']
    st.table(metrics_df)
    
    fig = go.Figure()
    fig.add_trace(
        go.Scatter(
            x=y_test,
            y=y_pred,
            mode='markers',
            name='ì˜ˆì¸¡ vs ì‹¤ì œ',
            marker=dict(color='blue', opacity=0.5)
        )
    )
    fig.add_trace(
        go.Scatter(
            x=[y_test.min(), y_test.max()],
            y=[y_test.min(), y_test.max()],
            mode='lines',
            name='ì´ìƒì ì¸ ì˜ˆì¸¡',
            line=dict(color='red', dash='dash')
        )
    )
    fig.update_layout(
        title='ì˜ˆì¸¡ vs ì‹¤ì œ ê°’ ë¹„êµ',
        xaxis_title='ì‹¤ì œ ê°’',
        yaxis_title='ì˜ˆì¸¡ ê°’'
    )
    st.plotly_chart(fig)
    
    return metrics

def calculate_risk_metrics(data, signals):
    try:
        risk_metrics = {}
        
        # ë³€ë™ì„± ê³„ì‚°
        returns = data['Close'].pct_change()
        volatility = returns.rolling(20).std() * np.sqrt(252)
        risk_metrics['Volatility'] = float(volatility.iloc[-1])
        
        # ìƒ¤í”„ ë¹„ìœ¨ ê³„ì‚°
        risk_free_rate = 0.02
        excess_returns = returns - risk_free_rate/252
        if len(returns) > 0 and returns.std() > 0:
            risk_metrics['Sharpe_ratio'] = float((np.sqrt(252) * excess_returns.mean() / returns.std()))
        else:
            risk_metrics['Sharpe_ratio'] = 0.0
        
        # ìµœëŒ€ ë‚™í­ ê³„ì‚°
        rolling_max = data['Close'].rolling(252, min_periods=1).max()
        drawdown = (data['Close'] - rolling_max) / rolling_max
        risk_metrics['Max_drawdown'] = float(drawdown.min())
        
        return risk_metrics
        
    except Exception as e:
        st.error(f"ë¦¬ìŠ¤í¬ ë©”íŠ¸ë¦­ìŠ¤ ê³„ì‚° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None

class TechnicalAnalyzer:
    def __init__(self, data):
        self.data = data
        self.features = []
    
    def calculate_indicators(self):
        try:
            df = self.data.copy()
            
            # ì´ë™í‰ê· ì„ 
            for period in [5, 10, 20, 50, 200]:
                df[f'SMA_{period}'] = df['Close'].rolling(window=period).mean()
                df[f'EMA_{period}'] = df['Close'].ewm(span=period, adjust=False).mean()
            
            # ë³¼ë¦°ì € ë°´ë“œ
            for period in [20]:
                df[f'BB_middle_{period}'] = df['Close'].rolling(window=period).mean()
                df[f'BB_upper_{period}'] = df[f'BB_middle_{period}'] + 2 * df['Close'].rolling(window=period).std()
                df[f'BB_lower_{period}'] = df[f'BB_middle_{period}'] - 2 * df['Close'].rolling(window=period).std()
                df[f'BB_width_{period}'] = (df[f'BB_upper_{period}'] - df[f'BB_lower_{period}']) / df[f'BB_middle_{period}']
            
            # RSI
            delta = df['Close'].diff()
            gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
            loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
            rs = gain / loss
            df['RSI'] = 100 - (100 / (1 + rs))
            
            # MACD
            exp1 = df['Close'].ewm(span=12, adjust=False).mean()
            exp2 = df['Close'].ewm(span=26, adjust=False).mean()
            df['MACD'] = exp1 - exp2
            df['Signal_Line'] = df['MACD'].ewm(span=9, adjust=False).mean()
            df['MACD_Histogram'] = df['MACD'] - df['Signal_Line']
            
            # ìŠ¤í† ìºìŠ¤í‹±
            low_14 = df['Low'].rolling(window=14).min()
            high_14 = df['High'].rolling(window=14).max()
            df['K_percent'] = 100 * ((df['Close'] - low_14) / (high_14 - low_14))
            df['D_percent'] = df['K_percent'].rolling(window=3).mean()
            
            # ADX
            plus_dm = df['High'].diff()
            minus_dm = df['Low'].diff()
            plus_dm[plus_dm < 0] = 0
            minus_dm[minus_dm > 0] = 0
            tr1 = df['High'] - df['Low']
            tr2 = abs(df['High'] - df['Close'].shift(1))
            tr3 = abs(df['Low'] - df['Close'].shift(1))
            tr = pd.concat([tr1, tr2, tr3], axis=1).max(axis=1)
            atr = tr.rolling(window=14).mean()
            plus_di = 100 * (plus_dm.rolling(window=14).mean() / atr)
            minus_di = 100 * (minus_dm.rolling(window=14).mean() / atr)
            dx = 100 * abs(plus_di - minus_di) / (plus_di + minus_di)
            df['ADX'] = dx.rolling(window=14).mean()
            
            # OBV
            df['OBV'] = (np.sign(df['Close'].diff()) * df['Volume']).fillna(0).cumsum()
            
            # ëª¨ë©˜í…€ ì§€í‘œ
            df['ROC'] = df['Close'].pct_change(periods=12) * 100
            df['MOM'] = df['Close'].diff(periods=10)
            
            # ì¶”ê°€ ë³€ë™ì„± ì§€í‘œ
            df['ATR'] = self.calculate_atr(df)
            df['Volatility'] = df['Close'].pct_change().rolling(window=20).std() * np.sqrt(252)
            
            # ê±°ë˜ëŸ‰ ì§€í‘œ
            df['Volume_MA'] = df['Volume'].rolling(window=20).mean()
            df['Volume_Ratio'] = df['Volume'] / df['Volume_MA']
            
            # ê°€ê²© ëª¨ë©˜í…€
            df['Price_Change'] = df['Close'].pct_change()
            df['Price_Change_Ratio'] = df['Close'] / df['Close'].rolling(window=20).mean()
            
            # í”¼ë³´ë‚˜ì¹˜ ë ˆë²¨ ê³„ì‚°
            high = df['High'].rolling(window=20).max()
            low = df['Low'].rolling(window=20).min()
            diff = high - low
            df['Fib_23.6'] = high - (diff * 0.236)
            df['Fib_38.2'] = high - (diff * 0.382)
            df['Fib_50.0'] = high - (diff * 0.500)
            df['Fib_61.8'] = high - (diff * 0.618)
            
            # ê²°ì¸¡ì¹˜ ì²˜ë¦¬
            df.fillna(method='bfill', inplace=True)
            df.fillna(method='ffill', inplace=True)
            
            self.data = df
            self.features = [col for col in df.columns if col not in ['Open', 'High', 'Low', 'Close', 'Volume']]
            
            return df
            
        except Exception as e:
            st.error(f"ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return None

    def calculate_atr(self, df, period=14):
        try:
            high_low = df['High'] - df['Low']
            high_close = np.abs(df['High'] - df['Close'].shift())
            low_close = np.abs(df['Low'] - df['Close'].shift())
            ranges = pd.concat([high_low, high_close, low_close], axis=1)
            true_range = ranges.max(axis=1)
            atr = true_range.rolling(period).mean()
            return atr
        except Exception as e:
            st.error(f"ATR ê³„ì‚° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return pd.Series(0, index=df.index)

    def get_trading_signals(self):
        """ê¸°ìˆ ì  ì§€í‘œ ê¸°ë°˜ ë§¤ë§¤ ì‹ í˜¸ ìƒì„±"""
        try:
            signals = pd.DataFrame(index=self.data.index)
            
            # RSI ê¸°ë°˜ ì‹ í˜¸
            signals['RSI_Signal'] = 0
            signals.loc[self.data['RSI'] < 30, 'RSI_Signal'] = 1  # ë§¤ìˆ˜
            signals.loc[self.data['RSI'] > 70, 'RSI_Signal'] = -1  # ë§¤ë„
            
            # MACD ê¸°ë°˜ ì‹ í˜¸
            signals['MACD_Signal'] = 0
            signals.loc[self.data['MACD'] > self.data['Signal_Line'], 'MACD_Signal'] = 1
            signals.loc[self.data['MACD'] < self.data['Signal_Line'], 'MACD_Signal'] = -1
            
            # ë³¼ë¦°ì € ë°´ë“œ ê¸°ë°˜ ì‹ í˜¸
            signals['BB_Signal'] = 0
            signals.loc[self.data['Close'] < self.data['BB_lower_20'], 'BB_Signal'] = 1
            signals.loc[self.data['Close'] > self.data['BB_upper_20'], 'BB_Signal'] = -1
            
            # ì´ë™í‰ê·  í¬ë¡œìŠ¤ ì‹ í˜¸
            signals['MA_Cross_Signal'] = 0
            signals.loc[self.data['SMA_5'] > self.data['SMA_20'], 'MA_Cross_Signal'] = 1
            signals.loc[self.data['SMA_5'] < self.data['SMA_20'], 'MA_Cross_Signal'] = -1
            
            # ì¢…í•© ì‹ í˜¸ ê³„ì‚°
            signals['Total_Signal'] = (signals['RSI_Signal'] + 
                                     signals['MACD_Signal'] + 
                                     signals['BB_Signal'] + 
                                     signals['MA_Cross_Signal'])
            
            # ìµœì¢… ë§¤ë§¤ ì‹ í˜¸
            signals['Final_Signal'] = 'HOLD'
            signals.loc[signals['Total_Signal'] >= 2, 'Final_Signal'] = 'BUY'
            signals.loc[signals['Total_Signal'] <= -2, 'Final_Signal'] = 'SELL'
            
            return signals
            
        except Exception as e:
            st.error(f"ë§¤ë§¤ ì‹ í˜¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return None

class ProbabilisticAnalyzer:
    def __init__(self, data, test_size=0.2, sequence_length=10):
        self.data = data
        self.test_size = test_size
        self.sequence_length = sequence_length
        self.models = {}
        self.predictions = {}
        self.signal_probabilities = {}
        
        # ë°ì´í„° ì¤€ë¹„
        self.X_train = None
        self.X_test = None
        self.y_train = None
        self.y_test = None
        
        # ìŠ¤ì¼€ì¼ë§ëœ ë°ì´í„°
        self.X_train_scaled = None
        self.X_test_scaled = None
        
        # ì‹œí€€ìŠ¤ ë°ì´í„°
        self.X_train_seq = None
        self.X_test_seq = None
        self.y_train_seq = None
        self.y_test_seq = None
        
        # íšŒê·€ ë¶„ì„ìš© ë°ì´í„°
        self.X_train_reg = None
        self.X_test_reg = None
        self.y_train_reg = None
        self.y_test_reg = None
        
        # ìŠ¤ì¼€ì¼ëŸ¬ì™€ íŠ¹ì„± ë³€í™˜ê¸°
        self.scaler = None
        self.poly_features = None
        
        # ì´ˆê¸° íŠ¹ì„± ì¤€ë¹„
        self.prepare_features()

    def prepare_features(self):
        try:
            features = []
            df = self.data.copy()
            
            # Target ë³€ìˆ˜ ìƒì„± (ë‹¤ìŒ ë‚ ì˜ ì¢…ê°€ ë°©í–¥)
            df['Target'] = df['Close'].shift(-1) > df['Close']
            df['Target'] = df['Target'].astype(float)
            
            # ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚°
            df['Price_Change'] = df['Close'].pct_change()
            df['Volume_Change'] = df['Volume'].pct_change()
            df['ROC'] = df['Close'].pct_change(periods=12) * 100
            df['MOM'] = df['Close'].diff(periods=10)
            df['Volatility'] = df['Close'].pct_change().rolling(window=20).std()
            df['SMA_5'] = df['Close'].rolling(window=5).mean()
            df['SMA_20'] = df['Close'].rolling(window=20).mean()
            
            # MA Cross ì‹ í˜¸ ìƒì„±
            df['MA_Cross'] = 0
            df.loc[df['SMA_5'] > df['SMA_20'], 'MA_Cross'] = 1
            df.loc[df['SMA_5'] < df['SMA_20'], 'MA_Cross'] = -1
            
            features = ['Price_Change', 'Volume_Change', 'ROC', 'MOM', 'Volatility', 'MA_Cross']
            
            # ê²°ì¸¡ì¹˜ ì œê±° ë° ë°ì´í„° ë¶„í• 
            df = df.dropna()
            train_size = int(len(df) * (1 - self.test_size))
            train_data = df[:train_size]
            test_data = df[train_size:]
            
            # í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¤€ë¹„
            self.X_train = train_data[features]
            self.X_test = test_data[features]
            self.y_train = train_data['Target']
            self.y_test = test_data['Target']
            
            # ìŠ¤ì¼€ì¼ë§
            self.scaler = MinMaxScaler()
            self.X_train_scaled = self.scaler.fit_transform(self.X_train)
            self.X_test_scaled = self.scaler.transform(self.X_test)
            
            # ì‹œí€€ìŠ¤ ë°ì´í„° ìƒì„±
            self.X_train_seq = self.create_sequences(self.X_train_scaled)
            self.X_test_seq = self.create_sequences(self.X_test_scaled)
            self.y_train_seq = self.y_train[self.sequence_length:].values
            self.y_test_seq = self.y_test[self.sequence_length:].values
            
            # íšŒê·€ ë¶„ì„ìš© ë°ì´í„° ì¤€ë¹„ (ë‹¤ìŒ ë‚ ì˜ ìˆ˜ìµë¥ )
            train_returns = train_data['Close'].pct_change().shift(-1).dropna()
            test_returns = test_data['Close'].pct_change().shift(-1).dropna()
            
            # ë‹¤í•­ íŠ¹ì„± ìƒì„±
            self.poly_features = PolynomialFeatures(degree=2, include_bias=False)
            X_train_poly = self.poly_features.fit_transform(self.X_train_scaled)
            X_test_poly = self.poly_features.transform(self.X_test_scaled)
            
            # íšŒê·€ ë¶„ì„ìš© ë°ì´í„° ìµœì¢… ì¤€ë¹„
            self.X_train_reg = X_train_poly[:-1]
            self.X_test_reg = X_test_poly[:-1]
            self.y_train_reg = train_returns
            self.y_test_reg = test_returns
            
            # ë°ì´í„° ê¸¸ì´ ë§ì¶”ê¸°
            min_train_len = min(len(self.X_train_reg), len(self.y_train_reg))
            min_test_len = min(len(self.X_test_reg), len(self.y_test_reg))
            
            self.X_train_reg = self.X_train_reg[:min_train_len]
            self.y_train_reg = self.y_train_reg[:min_train_len]
            self.X_test_reg = self.X_test_reg[:min_test_len]
            self.y_test_reg = self.y_test_reg[:min_test_len]
            
            # ë°ì´í„° ìœ íš¨ì„± ê²€ì‚¬
            if (self.y_train_reg is None or len(self.y_train_reg) == 0 or 
                self.y_test_reg is None or len(self.y_test_reg) == 0):
                raise ValueError("íšŒê·€ ë¶„ì„ìš© íƒ€ê²Ÿ ë°ì´í„°ê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            
            st.success("íŠ¹ì„± ì¤€ë¹„ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
            return features
            
        except Exception as e:
            st.error(f"íŠ¹ì„± ì¤€ë¹„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            st.write("ë°ì´í„° í˜•íƒœ:", self.data.shape)
            return None
    
    def create_sequences(self, data):
        try:
            sequences = []
            for i in range(len(data) - self.sequence_length):
                sequence = data[i:(i + self.sequence_length)]
                sequences.append(sequence)
            return np.array(sequences)
        except Exception as e:
            st.error(f"ì‹œí€€ìŠ¤ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return np.array([])
    
    def calculate_model_probabilities(self):
        try:
            for name, model in self.models.items():
                predictions_df = pd.DataFrame(index=self.X_test.index)
                
                if name == 'Linear Regression':
                    raw_predictions = model.predict(self.X_test_reg)
                    predictions_df['Value'] = raw_predictions
                    predictions_df['Signal'] = 'HOLD'
                    
                    for idx in predictions_df.index:
                        value = predictions_df.at[idx, 'Value']
                        if value > 0.01:
                            predictions_df.at[idx, 'Signal'] = 'BUY'
                        elif value < -0.01:
                            predictions_df.at[idx, 'Signal'] = 'SELL'
                
                elif name == 'LSTM':
                    raw_predictions = model.predict(self.X_test_seq)
                    predictions_df['Value'] = raw_predictions.flatten()
                    predictions_df['Signal'] = 'HOLD'
                    
                    for idx in predictions_df.index:
                        value = predictions_df.at[idx, 'Value']
                        if value > 0.6:
                            predictions_df.at[idx, 'Signal'] = 'BUY'
                        elif value < 0.4:
                            predictions_df.at[idx, 'Signal'] = 'SELL'
                
                else:
                    probabilities = model.predict_proba(self.X_test_scaled)
                    predictions_df['Value'] = probabilities[:, 1]
                    predictions_df['Signal'] = 'HOLD'
                    
                    for idx in predictions_df.index:
                        value = predictions_df.at[idx, 'Value']
                        if value > 0.6:
                            predictions_df.at[idx, 'Signal'] = 'BUY'
                        elif value < 0.4:
                            predictions_df.at[idx, 'Signal'] = 'SELL'
                
                self.predictions[name] = predictions_df['Signal']
                
                # ì‹ í˜¸ í™•ë¥  ê³„ì‚°
                signal_counts = predictions_df['Signal'].value_counts()
                total_signals = len(predictions_df)
                
                self.signal_probabilities[name] = {
                    'BUY': float(signal_counts.get('BUY', 0)) / total_signals * 100,
                    'SELL': float(signal_counts.get('SELL', 0)) / total_signals * 100,
                    'HOLD': float(signal_counts.get('HOLD', 0)) / total_signals * 100
                }
            
            # ì‹ í˜¸ í™•ë¥  ì‹œê°í™”
            self.plot_signal_probabilities()
            return True
        
        except Exception as e:
            st.error(f"í™•ë¥  ê³„ì‚° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return False
    
    def plot_signal_probabilities(self):
        try:
            # ë°ì´í„° ì¤€ë¹„
            models = list(self.signal_probabilities.keys())
            signals = ['BUY', 'SELL', 'HOLD']
            
            fig = go.Figure()
            
            for signal in signals:
                values = [self.signal_probabilities[model][signal] for model in models]
                
                fig.add_trace(go.Bar(
                    name=signal,
                    x=models,
                    y=values,
                    text=[f"{v:.1f}%" for v in values],
                    textposition='auto',
                ))
            
            fig.update_layout(
                title='ëª¨ë¸ë³„ ì‹ í˜¸ í™•ë¥  ë¶„í¬',
                xaxis_title='ëª¨ë¸',
                yaxis_title='í™•ë¥  (%)',
                barmode='group',
                height=500,
                showlegend=True,
                legend=dict(
                    yanchor="top",
                    y=0.99,
                    xanchor="right",
                    x=0.99
                )
            )
            
            st.plotly_chart(fig)
            
            # ìƒì„¸ í™•ë¥  í‘œì‹œ
            st.write("### ëª¨ë¸ë³„ ì‹ í˜¸ í™•ë¥ ")
            prob_df = pd.DataFrame(self.signal_probabilities).round(2)
            st.dataframe(
                prob_df.style
                .format("{:.2f}%")
                .background_gradient(cmap='YlOrRd')
            )
            
        except Exception as e:
            st.error(f"ì‹ í˜¸ í™•ë¥  ì‹œê°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

    def train_models(self):
        try:
            self.models = {}
            
            # Linear Regression
            lr_model = LinearRegression()
            lr_model.fit(self.X_train_reg, self.y_train_reg)
            self.models['Linear Regression'] = lr_model
            
            # Random Forest
            rf_model = RandomForestClassifier(
                n_estimators=100,
                max_depth=10,
                random_state=42
            )
            rf_model.fit(self.X_train_scaled, self.y_train)
            self.models['Random Forest'] = rf_model
            
            # XGBoost
            xgb_model = XGBClassifier(
                n_estimators=100,
                max_depth=6,
                learning_rate=0.1,
                random_state=42
            )
            xgb_model.fit(self.X_train_scaled, self.y_train)
            self.models['XGBoost'] = xgb_model
            
            # LightGBM
            lgbm_model = LGBMClassifier(
                n_estimators=100,
                max_depth=6,
                learning_rate=0.1,
                random_state=42
            )
            lgbm_model.fit(self.X_train_scaled, self.y_train)
            self.models['LightGBM'] = lgbm_model
            
            # LSTM
            lstm_model = self.build_lstm_model()
            lstm_model.fit(
                self.X_train_seq,
                self.y_train_seq,
                epochs=50,
                batch_size=32,
                validation_split=0.2,
                verbose=0
            )
            self.models['LSTM'] = lstm_model
            
            st.success("ëª¨ë“  ëª¨ë¸ í•™ìŠµì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
            return True
            
        except Exception as e:
            st.error(f"ëª¨ë¸ í•™ìŠµ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return False

    def predict_future(self, days=30):
        try:
            future_predictions = {}
            last_data = self.data.iloc[-self.sequence_length:]
            
            for name, model in self.models.items():
                predictions = []
                current_data = last_data.copy()
                
                for _ in range(days):
                    # íŠ¹ì„± ì¤€ë¹„
                    features = self.prepare_prediction_features(current_data)
                    
                    if name == 'Linear Regression':
                        features_poly = self.poly_features.transform(features)
                        pred = model.predict(features_poly)[-1]
                        
                    elif name == 'LSTM':
                        seq = self.create_sequences(features)
                        if len(seq) > 0:
                            pred = model.predict(seq)[-1][0]
                        else:
                            continue
                            
                    else:
                        features_scaled = self.scaler.transform(features)
                        pred = model.predict_proba(features_scaled)[-1][1]
                    
                    predictions.append(pred)
                    
                    # ë‹¤ìŒ ì˜ˆì¸¡ì„ ìœ„í•œ ë°ì´í„° ì—…ë°ì´íŠ¸
                    new_row = current_data.iloc[-1].copy()
                    new_row['Close'] = current_data['Close'].iloc[-1] * (1 + pred)
                    current_data = pd.concat([current_data[1:], pd.DataFrame([new_row])])
                    current_data.index = pd.date_range(
                        start=current_data.index[0],
                        periods=len(current_data),
                        freq='D'
                    )
                
                future_predictions[name] = predictions
            
            # ì˜ˆì¸¡ ê²°ê³¼ ì‹œê°í™”
            self.plot_future_predictions(future_predictions, days)
            
            return future_predictions
            
        except Exception as e:
            st.error(f"ë¯¸ë˜ ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return None

    def prepare_prediction_features(self, data):
        try:
            df = data.copy()
            
            # ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚°
            df['Price_Change'] = df['Close'].pct_change()
            df['Volume_Change'] = df['Volume'].pct_change()
            df['ROC'] = df['Close'].pct_change(periods=12) * 100
            df['MOM'] = df['Close'].diff(periods=10)
            df['Volatility'] = df['Close'].pct_change().rolling(window=20).std()
            df['SMA_5'] = df['Close'].rolling(window=5).mean()
            df['SMA_20'] = df['Close'].rolling(window=20).mean()
            
            # MA Cross ì‹ í˜¸
            df['MA_Cross'] = 0
            df.loc[df['SMA_5'] > df['SMA_20'], 'MA_Cross'] = 1
            df.loc[df['SMA_5'] < df['SMA_20'], 'MA_Cross'] = -1
            
            features = ['Price_Change', 'Volume_Change', 'ROC', 'MOM', 'Volatility', 'MA_Cross']
            
            return df[features].fillna(method='ffill')
            
        except Exception as e:
            st.error(f"ì˜ˆì¸¡ íŠ¹ì„± ì¤€ë¹„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return None

    def plot_future_predictions(self, future_predictions, days):
        try:
            # ê³¼ê±° ë°ì´í„° ì¤€ë¹„
            historical_dates = self.data.index[-30:]  # ìµœê·¼ 30ì¼
            historical_prices = self.data['Close'].iloc[-30:]
            
            # ë¯¸ë˜ ë‚ ì§œ ìƒì„±
            last_date = self.data.index[-1]
            future_dates = pd.date_range(start=last_date + pd.Timedelta(days=1), periods=days)
            
            # ê·¸ë˜í”„ ìƒì„±
            fig = go.Figure()
            
            # ê³¼ê±° ë°ì´í„° í”Œë¡¯
            fig.add_trace(go.Scatter(
                x=historical_dates,
                y=historical_prices,
                name='ê³¼ê±° ë°ì´í„°',
                line=dict(color='gray')
            ))
            
            # ê° ëª¨ë¸ì˜ ì˜ˆì¸¡ê°’ í”Œë¡¯
            for name, predictions in future_predictions.items():
                # ì˜ˆì¸¡ê°’ì„ ì‹¤ì œ ê°€ê²©ìœ¼ë¡œ ë³€í™˜
                last_price = historical_prices.iloc[-1]
                predicted_prices = []
                current_price = last_price
                
                for pred in predictions:
                    if name == 'Linear Regression':
                        current_price = current_price * (1 + pred)
                    else:
                        # ë¶„ë¥˜ ëª¨ë¸ì˜ ê²½ìš° í™•ë¥ ì„ ê°€ê²© ë³€í™”ë¡œ ë³€í™˜
                        price_change = (pred - 0.5) * 0.02  # 2% ìµœëŒ€ ë³€í™”
                        current_price = current_price * (1 + price_change)
                    predicted_prices.append(current_price)
                
                fig.add_trace(go.Scatter(
                    x=future_dates,
                    y=predicted_prices,
                    name=f'{name} ì˜ˆì¸¡',
                    line=dict(dash='dash')
                ))
            
            # ë ˆì´ì•„ì›ƒ ì„¤ì •
            fig.update_layout(
                title='ì£¼ê°€ ì˜ˆì¸¡ ê²°ê³¼',
                xaxis_title='ë‚ ì§œ',
                yaxis_title='ê°€ê²©',
                height=600,
                showlegend=True,
                legend=dict(
                    yanchor="top",
                    y=0.99,
                    xanchor="left",
                    x=0.01
                )
            )
            
            # ê·¸ë¦¬ë“œ ì¶”ê°€
            fig.update_xaxes(showgrid=True, gridwidth=1, gridcolor='LightGray')
            fig.update_yaxes(showgrid=True, gridwidth=1, gridcolor='LightGray')
            
            st.plotly_chart(fig)
            
            # ì˜ˆì¸¡ ì‹ ë¢°ë„ í‘œì‹œ
            confidence_df = pd.DataFrame(columns=['ëª¨ë¸', 'ì˜ˆì¸¡ ë°©í–¥', 'ì‹ ë¢°ë„'])
            for name, predictions in future_predictions.items():
                if len(predictions) > 0:
                    last_pred = predictions[-1]
                    if name == 'Linear Regression':
                        direction = 'ìƒìŠ¹' if last_pred > 0 else 'í•˜ë½'
                        confidence = abs(last_pred) * 100
                    else:
                        direction = 'ìƒìŠ¹' if last_pred > 0.5 else 'í•˜ë½'
                        confidence = abs(last_pred - 0.5) * 200
                    
                    confidence_df = pd.concat([confidence_df, pd.DataFrame({
                        'ëª¨ë¸': [name],
                        'ì˜ˆì¸¡ ë°©í–¥': [direction],
                        'ì‹ ë¢°ë„': [f"{min(confidence, 100):.1f}%"]
                    })])
            
            st.write("### ì˜ˆì¸¡ ì‹ ë¢°ë„")
            st.dataframe(confidence_df.set_index('ëª¨ë¸'))
            
        except Exception as e:
            st.error(f"ë¯¸ë˜ ì˜ˆì¸¡ ì‹œê°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return None

    def build_lstm_model(self):
        try:
            # ì…ë ¥ í˜•íƒœ ê²€ì¦
            if not hasattr(self, 'sequence_length') or not hasattr(self, 'X_train'):
                raise ValueError("ì‹œí€€ìŠ¤ ê¸¸ì´ ë˜ëŠ” í•™ìŠµ ë°ì´í„°ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            
            # ì…ë ¥ ì°¨ì› ê³„ì‚°
            input_dim = self.X_train.shape[1] if hasattr(self, 'X_train') else 1
            
            # LSTM ëª¨ë¸ êµ¬ì„± - ë‹¨ìˆœí™”ëœ ë²„ì „
            model = Sequential([
                LSTM(
                    units=64,
                    activation='tanh',  # ReLU ëŒ€ì‹  tanh ì‚¬ìš©
                    input_shape=(self.sequence_length, input_dim),
                    return_sequences=False,
                    kernel_initializer='glorot_uniform'
                ),
                Dropout(0.3),
                Dense(32, activation='relu'),
                Dropout(0.2),
                Dense(1, activation='sigmoid')
            ])
            
            # ëª¨ë¸ ì»´íŒŒì¼ - í•™ìŠµë¥  ì¡°ì •
            optimizer = Adam(learning_rate=0.0005)
            model.compile(
                optimizer=optimizer,
                loss='binary_crossentropy',
                metrics=['accuracy']
            )
            
            # Early Stopping ì½œë°± ì„¤ì •
            early_stopping = EarlyStopping(
                monitor='val_loss',
                patience=5,  # ì¸ë‚´ì‹¬ ê°ì†Œ
                restore_best_weights=True,
                mode='min'
            )
            
            # ëª¨ë¸ ì†ì„±ì— ì½œë°± ì €ì¥
            self.callbacks = [early_stopping]
            
            return model
            
        except Exception as e:
            st.error(f"LSTM ëª¨ë¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            st.info("ê¸°ë³¸ LSTM ëª¨ë¸ì„ ìƒì„±í•©ë‹ˆë‹¤.")
            
            # ë” ë‹¨ìˆœí•œ ê¸°ë³¸ LSTM ëª¨ë¸ ìƒì„±
            default_model = Sequential([
                LSTM(32, input_shape=(self.sequence_length, input_dim), activation='tanh'),
                Dense(1, activation='sigmoid')
            ])
            default_model.compile(
                optimizer='adam',
                loss='binary_crossentropy',
                metrics=['accuracy']
            )
            return default_model

    def compare_models(self):
        """ëª¨ë¸ë³„ ì„±ëŠ¥ ë¹„êµ ì‹œê°í™”"""
        try:
            if not hasattr(self, 'models'):
                st.warning("í•™ìŠµëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
                return None
            
            # ê° ëª¨ë¸ë³„ ì„±ëŠ¥ ë¶„ì„
            for name, model in self.models.items():
                with st.expander(f"ğŸ“Š {name} ëª¨ë¸ ë¶„ì„ ê²°ê³¼"):
                    try:
                        # ê¸°ë³¸ ì„±ëŠ¥ ì§€í‘œ ê³„ì‚°
                        metrics = {}
                        if name == 'Linear Regression':
                            y_pred = model.predict(self.X_test_reg)
                            metrics['R2'] = r2_score(self.y_test_reg, y_pred)
                            metrics['MAE'] = mean_absolute_error(self.y_test_reg, y_pred)
                            metrics['RMSE'] = np.sqrt(mean_squared_error(self.y_test_reg, y_pred))
                            
                            # ë°©í–¥ì„± ì •í™•ë„ ê³„ì‚°
                            correct_direction = np.sum(
                                (y_pred > 0) == (self.y_test_reg.values > 0)
                            )
                            metrics['ë°©í–¥ì„± ì •í™•ë„'] = (correct_direction / len(y_pred)) * 100
                            
                        elif name == 'LSTM':
                            y_pred = model.predict(self.X_test_seq)
                            metrics['Accuracy'] = accuracy_score(self.y_test_seq, (y_pred > 0.5).astype(int))
                            metrics['Precision'] = precision_score(self.y_test_seq, (y_pred > 0.5).astype(int))
                            metrics['Recall'] = recall_score(self.y_test_seq, (y_pred > 0.5).astype(int))
                            metrics['F1'] = f1_score(self.y_test_seq, (y_pred > 0.5).astype(int))
                            
                        elif name in ['Random Forest', 'XGBoost', 'LightGBM']:
                            y_pred = model.predict(self.X_test)
                            metrics['Accuracy'] = accuracy_score(self.y_test, y_pred)
                            metrics['Precision'] = precision_score(self.y_test, y_pred)
                            metrics['Recall'] = recall_score(self.y_test, y_pred)
                            metrics['F1'] = f1_score(self.y_test, y_pred)
                            
                            if hasattr(model, 'feature_importances_'):
                                feature_importance = pd.DataFrame({
                                    'Feature': self.X_train.columns,
                                    'Importance': model.feature_importances_
                                })
                                feature_importance = feature_importance.sort_values('Importance', ascending=False)
                                
                                st.write("#### ì£¼ìš” íŠ¹ì„± ì¤‘ìš”ë„")
                                fig = go.Figure()
                                fig.add_trace(go.Bar(
                                    x=feature_importance['Feature'][:10],
                                    y=feature_importance['Importance'][:10],
                                    name='íŠ¹ì„± ì¤‘ìš”ë„'
                                ))
                                fig.update_layout(
                                    title='ìƒìœ„ 10ê°œ íŠ¹ì„± ì¤‘ìš”ë„',
                                    xaxis_title='íŠ¹ì„±',
                                    yaxis_title='ì¤‘ìš”ë„',
                                    xaxis=dict(tickangle=45)
                                )
                                st.plotly_chart(fig)
                        
                        # ì„±ëŠ¥ ì§€í‘œ í‘œì‹œ
                        st.write("#### ëª¨ë¸ ì„±ëŠ¥ ì§€í‘œ")
                        metrics_df = pd.DataFrame.from_dict(metrics, orient='index', columns=['ê°’'])
                        st.dataframe(
                            metrics_df.style
                            .format({'ê°’': '{:.4f}'})
                            .background_gradient(cmap='YlOrRd')
                        )
                        
                        # AI ì „ë¬¸ê°€ ë¶„ì„
                        st.write("#### AI ì „ë¬¸ê°€ ë¶„ì„")
                        analysis = analyze_model_performance(metrics)
                        st.markdown(analysis)
                        
                    except Exception as model_error:
                        st.error(f"{name} ëª¨ë¸ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(model_error)}")
                        continue
            
            # ëª¨ë¸ ê°„ ì„±ëŠ¥ ë¹„êµ ì‹œê°í™”
            st.write("### ëª¨ë¸ ê°„ ì„±ëŠ¥ ë¹„êµ")
            comparison_metrics = {}
            for name, model in self.models.items():
                if name == 'Linear Regression':
                    y_pred = model.predict(self.X_test_reg)
                    comparison_metrics[name] = {
                        'ë°©í–¥ì„± ì •í™•ë„': (np.sum((y_pred > 0) == (self.y_test_reg.values > 0)) / len(y_pred)) * 100
                    }
                else:
                    y_pred = model.predict(self.X_test if name not in ['LSTM'] else self.X_test_seq)
                    y_true = self.y_test if name not in ['LSTM'] else self.y_test_seq
                    comparison_metrics[name] = {
                        'Accuracy': accuracy_score(y_true, (y_pred > 0.5).astype(int) if name == 'LSTM' else y_pred) * 100
                    }
            
            # ë¹„êµ ì°¨íŠ¸ ìƒì„±
            comparison_df = pd.DataFrame(comparison_metrics).T
            fig = go.Figure()
            for col in comparison_df.columns:
                fig.add_trace(go.Bar(
                    name=col,
                    x=comparison_df.index,
                    y=comparison_df[col],
                    text=comparison_df[col].round(2).astype(str) + '%',
                    textposition='auto',
                ))
            
            fig.update_layout(
                title='ëª¨ë¸ë³„ ì„±ëŠ¥ ë¹„êµ',
                yaxis_title='ì •í™•ë„ (%)',
                barmode='group',
                showlegend=True
            )
            st.plotly_chart(fig)
            
        except Exception as e:
            st.error(f"ëª¨ë¸ ë¹„êµ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return None

    def plot_feature_importance(self):
        try:
            st.write("### ëª¨ë¸ë³„ íŠ¹ì„± ì¤‘ìš”ë„ ë¶„ì„")
            for name, model in self.models.items():
                try:
                    if name == 'Linear Regression':
                        # íŠ¹ì„± ì´ë¦„ì„ ë¬¸ìì—´ë¡œ ì ì ˆíˆ ë³€í™˜
                        raw_feature_names = self.poly_features.get_feature_names_out(self.X_train.columns)
                        feature_names = []
                        for feat in raw_feature_names:
                            feat_str = str(feat)
                            if isinstance(feat, (tuple, list)):
                                feat_str = ' * '.join(map(str, feat))
                            feature_names.append(feat_str)
                        importance = np.abs(model.coef_)
                    elif name == 'LSTM':
                        continue  # LSTMì€ íŠ¹ì„± ì¤‘ìš”ë„ë¥¼ ì œê³µí•˜ì§€ ì•ŠìŒ
                    elif name in ['Random Forest', 'XGBoost', 'LightGBM']:
                        if not hasattr(model, 'feature_importances_'):
                            continue
                        feature_names = [str(col) for col in self.X_train.columns]
                        importance = model.feature_importances_
                    else:
                        continue
                    
                    # ë°ì´í„°í”„ë ˆì„ ìƒì„± ë° ì •ë ¬
                    importance_df = pd.DataFrame({
                        'Feature': feature_names,
                        'Importance': importance
                    })
                    importance_df = importance_df.sort_values('Importance', ascending=False).head(15)
                    
                    # Plotly ê·¸ë˜í”„ ìƒì„±
                    fig = go.Figure()
                    fig.add_trace(
                        go.Bar(
                            x=importance_df['Importance'],
                            y=importance_df['Feature'],
                            orientation='h',
                            marker=dict(
                                color=importance_df['Importance'],
                                colorscale='YlOrRd'
                            )
                        )
                    )
                    
                    fig.update_layout(
                        title=f'{name} ëª¨ë¸ì˜ íŠ¹ì„± ì¤‘ìš”ë„',
                        xaxis_title='ì¤‘ìš”ë„',
                        yaxis_title='íŠ¹ì„±',
                        height=600,
                        yaxis=dict(autorange="reversed")
                    )
                    st.plotly_chart(fig)
                    
                    # ìƒì„¸ ë°ì´í„° í‘œì‹œ
                    st.write(f"#### {name} ëª¨ë¸ì˜ íŠ¹ì„± ì¤‘ìš”ë„ ìƒì„¸")
                    st.dataframe(
                        importance_df.style
                        .background_gradient(cmap='YlOrRd', subset=['Importance'])
                    )
                    
                except Exception as model_error:
                    st.warning(f"{name} ëª¨ë¸ì˜ íŠ¹ì„± ì¤‘ìš”ë„ë¥¼ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {str(model_error)}")
                    continue
                
        except Exception as e:
            st.error(f"íŠ¹ì„± ì¤‘ìš”ë„ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

    def plot_roc_curves(self):
        try:
            st.write("### ëª¨ë¸ë³„ ROC ê³¡ì„  ë¹„êµ")
            fig = go.Figure()
            auc_scores = {}
            
            # ê¸°ì¤€ì„  ì¶”ê°€
            fig.add_trace(
                go.Scatter(
                    x=[0, 1],
                    y=[0, 1],
                    line=dict(dash='dash', color='gray'),
                    name='Random Classifier'
                )
            )
            
            for name, model in self.models.items():
                try:
                    if name == 'Linear Regression':
                        y_pred = model.predict(self.X_test_reg)
                        y_true = (self.y_test_reg.values > 0).astype(int)  # ìˆ˜ìµë¥ ì˜ ë°©í–¥ì„ ê¸°ì¤€ìœ¼ë¡œ ì´ì§„ ë¶„ë¥˜
                        y_score = (y_pred - np.min(y_pred)) / (np.max(y_pred) - np.min(y_pred))
                    
                    elif name == 'LSTM':
                        y_true = self.y_test_seq
                        y_score = model.predict(self.X_test_seq).ravel()
                    
                    else:
                        y_true = self.y_test.values  # numpy arrayë¡œ ë³€í™˜
                        y_score = model.predict_proba(self.X_test_scaled)[:, 1]
                    
                    # ROC ê³¡ì„  ê³„ì‚°
                    fpr, tpr, _ = roc_curve(y_true, y_score)
                    auc_score = auc(fpr, tpr)
                    auc_scores[name] = auc_score
                    
                    # ROC ê³¡ì„  ì¶”ê°€
                    fig.add_trace(
                        go.Scatter(
                            x=fpr,
                            y=tpr,
                            name=f'{name} (AUC = {auc_score:.3f})',
                            mode='lines'
                        )
                    )
                    
                except Exception as model_error:
                    st.warning(f"{name} ëª¨ë¸ì˜ ROC ê³¡ì„ ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {str(model_error)}")
                    continue
                
            # ê·¸ë˜í”„ ë ˆì´ì•„ì›ƒ ì„¤ì •
            fig.update_layout(
                title='ROC Curves Comparison',
                xaxis_title='False Positive Rate',
                yaxis_title='True Positive Rate',
                height=600,
                width=800,
                showlegend=True,
                legend=dict(
                    yanchor="bottom",
                    y=0.01,
                    xanchor="right",
                    x=0.99
                )
            )
            
            # ê·¸ë¦¬ë“œ ì¶”ê°€
            fig.update_xaxes(showgrid=True, gridwidth=1, gridcolor='LightGray')
            fig.update_yaxes(showgrid=True, gridwidth=1, gridcolor='LightGray')
            
            # ê·¸ë˜í”„ í‘œì‹œ
            st.plotly_chart(fig)
            
            # AUC ì ìˆ˜ í‘œì‹œ
            if auc_scores:
                st.write("### AUC ì ìˆ˜ ë¹„êµ")
                auc_df = pd.DataFrame(
                    auc_scores.items(),
                    columns=['ëª¨ë¸', 'AUC ì ìˆ˜']
                ).sort_values('AUC ì ìˆ˜', ascending=False)
                
                st.dataframe(
                    auc_df.style
                    .background_gradient(cmap='YlOrRd', subset=['AUC ì ìˆ˜'])
                    .format({'AUC ì ìˆ˜': '{:.4f}'})
                )
        except Exception as e:
            st.error(f"ROC ê³¡ì„  ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            st.info("ì¼ë¶€ ëª¨ë¸ì—ì„œ ROC ê³¡ì„ ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    def plot_regression_analysis(self):
        """íšŒê·€ ë¶„ì„ ê²°ê³¼ë¥¼ ì‹œê°í™”í•©ë‹ˆë‹¤."""
        try:
            if not hasattr(self, 'models') or 'Linear Regression' not in self.models:
                st.warning("ì„ í˜• íšŒê·€ ëª¨ë¸ì´ í•™ìŠµë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                return None
            
            # ê¸°ì¡´ íšŒê·€ ë¶„ì„ ì‹œê°í™” ì½”ë“œ
            X_test_reg = self.X_test_reg
            y_test_reg = self.y_test_reg
            
            if X_test_reg is None or y_test_reg is None:
                st.warning("í…ŒìŠ¤íŠ¸ ë°ì´í„°ê°€ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                return None
            
            # ì˜ˆì¸¡ê°’ ê³„ì‚°
            try:
                y_pred = self.models['Linear Regression'].predict(X_test_reg)
                
                # ì°¨ì› ì¼ì¹˜ í™•ì¸ ë° ì¡°ì •
                if len(y_pred.shape) > 1:
                    y_pred = y_pred.flatten()
                
                # ì‚°ì ë„ ë° íšŒê·€ì„  ê·¸ë˜í”„
                fig = go.Figure()
                
                # ì‹¤ì œ ê°’ê³¼ ì˜ˆì¸¡ê°’ ì‚°ì ë„
                fig.add_trace(go.Scatter(
                    x=y_test_reg,
                    y=y_pred,
                    mode='markers',
                    name='ì‹¤ì œ vs ì˜ˆì¸¡',
                    marker=dict(
                        size=8,
                        color='blue',
                        opacity=0.6
                    )
                ))
                
                # ì´ìƒì ì¸ ì˜ˆì¸¡ì„  (y=x)
                min_val = min(min(y_test_reg), min(y_pred))
                max_val = max(max(y_test_reg), max(y_pred))
                fig.add_trace(go.Scatter(
                    x=[min_val, max_val],
                    y=[min_val, max_val],
                    mode='lines',
                    name='ì´ìƒì ì¸ ì˜ˆì¸¡',
                    line=dict(color='red', dash='dash')
                ))
                
                # ê·¸ë˜í”„ ë ˆì´ì•„ì›ƒ ì„¤ì •
                fig.update_layout(
                    title='ì‹¤ì œ ê°’ vs ì˜ˆì¸¡ ê°’ ë¹„êµ',
                    xaxis_title='ì‹¤ì œ ê°’',
                    yaxis_title='ì˜ˆì¸¡ ê°’',
                    showlegend=True
                )
                
                # ê·¸ë¦¬ë“œ ì¶”ê°€
                fig.update_xaxes(showgrid=True, gridwidth=1, gridcolor='LightGray')
                fig.update_yaxes(showgrid=True, gridwidth=1, gridcolor='LightGray')
                
                # ê·¸ë˜í”„ í‘œì‹œ
                st.plotly_chart(fig)
                
                # íšŒê·€ ë¶„ì„ ì„±ëŠ¥ ì§€í‘œ ê³„ì‚°
                metrics = {
                    'R2': r2_score(y_test_reg, y_pred),
                    'MAE': mean_absolute_error(y_test_reg, y_pred),
                    'MSE': mean_squared_error(y_test_reg, y_pred),
                    'RMSE': np.sqrt(mean_squared_error(y_test_reg, y_pred))
                }
                
                # íšŒê·€ ë¶„ì„ ê²°ê³¼ í•´ì„ expander ì¶”ê°€
                with st.expander("ğŸ“Š ì„ í˜• íšŒê·€ ë¶„ì„ ê²°ê³¼ í•´ì„"):
                    st.write("#### ëª¨ë¸ ì„±ëŠ¥ ì§€í‘œ")
                    metrics_df = pd.DataFrame.from_dict(metrics, orient='index', columns=['ê°’'])
                    st.dataframe(
                        metrics_df.style
                        .format({'ê°’': '{:.4f}'})
                        .background_gradient(cmap='YlOrRd')
                    )
                    
                    # GPT-4ë¥¼ ì‚¬ìš©í•œ ìƒì„¸ ë¶„ì„
                    st.write("#### ì „ë¬¸ê°€ ë¶„ì„")
                    analysis = analyze_model_performance(metrics)
                    st.markdown(analysis)
                    
                    st.write("#### ì£¼ìš” íŠ¹ì„± ì¤‘ìš”ë„")
                    if hasattr(self.models['Linear Regression'], 'coef_'):
                        coef = self.models['Linear Regression'].coef_
                        # ë‹¤í•­ íŠ¹ì„±ì˜ ì´ë¦„ì„ ê°€ì ¸ì˜µë‹ˆë‹¤
                        feature_names = self.poly_features.get_feature_names_out(self.X_train.columns)
                        
                        # íŠ¹ì„± ì¤‘ìš”ë„ ë°ì´í„°í”„ë ˆì„ ìƒì„±
                        feature_importance = pd.DataFrame({
                            'Feature': feature_names,
                            'Importance': np.abs(coef)
                        })
                        feature_importance = feature_importance.sort_values('Importance', ascending=False)
                        
                        # ìƒìœ„ 10ê°œ íŠ¹ì„±ë§Œ ì„ íƒ
                        top_10_features = feature_importance.head(10)
                        
                        fig_importance = go.Figure()
                        fig_importance.add_trace(go.Bar(
                            x=top_10_features['Feature'],
                            y=top_10_features['Importance'],
                            name='íŠ¹ì„± ì¤‘ìš”ë„'
                        ))
                        fig_importance.update_layout(
                            title='ìƒìœ„ 10ê°œ íŠ¹ì„± ì¤‘ìš”ë„',
                            xaxis_title='íŠ¹ì„±',
                            yaxis_title='ì¤‘ìš”ë„',
                            xaxis=dict(tickangle=45)
                        )
                        st.plotly_chart(fig_importance)

            except Exception as e:
                st.error(f"íšŒê·€ ë¶„ì„ ì‹œê°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                return None
                
        except Exception as e:
            st.error(f"íšŒê·€ ë¶„ì„ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return None

    def plot_model_comparison(self):
        """ëª¨ë¸ë³„ ì„±ëŠ¥ ë¹„êµ ì‹œê°í™”"""
        try:
            if not self.performance_metrics:
                return None, pd.DataFrame()

            # ì„±ëŠ¥ ì§€í‘œ ë°ì´í„°í”„ë ˆì„ ìƒì„±
            comparison_data = []
            for name, metrics in self.performance_metrics.items():
                row_data = {
                    'Model': name,
                    'Current Signal': self.predictions[name].iloc[-1] if name in self.predictions else 'HOLD',
                    'Accuracy': f"{metrics.get('Win_Rate', 0):.2f}%",
                    'Cumulative Return': f"{metrics.get('Cumulative_Return', 0)*100:.2f}%",
                    'Sharpe Ratio': f"{metrics.get('Sharpe_Ratio', 0):.2f}",
                    'Risk Level': metrics.get('Risk_Level', 'MEDIUM')
                }
                comparison_data.append(row_data)

            comparison_df = pd.DataFrame(comparison_data)

            # ì‹œê°í™”
            fig = go.Figure()
            colors = {'BUY': 'green', 'SELL': 'red', 'HOLD': 'gray'}

            for signal in ['BUY', 'SELL', 'HOLD']:
                mask = comparison_df['Current Signal'] == signal
                if not any(mask):
                    continue

                fig.add_trace(go.Bar(
                    name=signal,
                    x=comparison_df[mask]['Model'],
                    y=[float(acc.strip('%')) for acc in comparison_df[mask]['Accuracy']],
                    marker_color=colors[signal]
                ))

            fig.update_layout(
                title='ëª¨ë¸ë³„ ì„±ëŠ¥ ë¹„êµ',
                xaxis_title='ëª¨ë¸',
                yaxis_title='ì •í™•ë„ (%)',
                barmode='group',
                showlegend=True,
                height=500
            )

            return fig, comparison_df

        except Exception as e:
            st.error(f"ëª¨ë¸ ë¹„êµ ì‹œê°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return None, pd.DataFrame()

class ModelSignalAnalyzer:
    def __init__(self, models, data, predictions):
        self.models = models
        self.data = data
        self.predictions = predictions
        self.performance_metrics = {}
        self.risk_free_rate = 0.02  # ì—°ê°„ ë¬´ìœ„í—˜ ìˆ˜ìµë¥  (ì˜ˆ: 2%)
        self.trading_days = 252  # ì—°ê°„ ê±°ë˜ì¼ìˆ˜
        self.returns = self.data['Close'].pct_change().fillna(0)

    def analyze_signals(self):
        """ëª¨ë¸ë³„ ë§¤ë§¤ ì‹ í˜¸ ë¶„ì„"""
        try:
            metrics = {}
            
            for name, signals in self.predictions.items():
                if signals is None or len(signals) == 0:
                    st.warning(f"{name} ëª¨ë¸ì˜ ì˜ˆì¸¡ ì‹ í˜¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
                    continue
                
                # í¬ì§€ì…˜ ì„¤ì • (1: ë§¤ìˆ˜, -1: ë§¤ë„, 0: ê´€ë§)
                positions = pd.Series(0, index=signals.index)
                positions[signals == 'BUY'] = 1
                positions[signals == 'SELL'] = -1
                
                # ìˆ˜ìµë¥  ê³„ì‚°
                strategy_returns = positions.shift(1) * self.returns  # ë‹¤ìŒë‚ ì˜ ìˆ˜ìµë¥ ì— ì ìš©
                strategy_returns = strategy_returns.fillna(0)
                
                # ê³ ê¸‰ ì§€í‘œ ê³„ì‚°
                try:
                    advanced_metrics = self.calculate_advanced_metrics(strategy_returns)
                    if advanced_metrics:
                        metrics[name] = advanced_metrics
                except Exception as e:
                    st.warning(f"{name} ëª¨ë¸ì˜ ì„±ëŠ¥ ì§€í‘œ ê³„ì‚° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                    continue
            
            if not metrics:
                st.warning("ëª¨ë“  ëª¨ë¸ì˜ ì„±ëŠ¥ ì§€í‘œ ê³„ì‚°ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                return None
            
            self.performance_metrics = metrics
            return metrics
            
        except Exception as e:
            st.error(f"ë§¤ë§¤ ì‹ í˜¸ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return None

    def calculate_advanced_metrics(self, strategy_returns):
        """ê³ ê¸‰ ì„±ëŠ¥ ì§€í‘œ ê³„ì‚°"""
        try:
            metrics = {}
            
            # ëˆ„ì  ìˆ˜ìµë¥ 
            cumulative_return = (1 + strategy_returns).cumprod().iloc[-1] - 1
            metrics['Cumulative_Return'] = cumulative_return
            
            # ë³€ë™ì„± (ì—°ìœ¨í™”)
            volatility = strategy_returns.std() * np.sqrt(self.trading_days)
            metrics['Volatility'] = volatility
            
            # ìƒ¤í”„ ë¹„ìœ¨
            excess_returns = strategy_returns - (self.risk_free_rate / self.trading_days)
            if len(strategy_returns) > 0 and strategy_returns.std() > 0:
                sharpe_ratio = np.sqrt(self.trading_days) * excess_returns.mean() / strategy_returns.std()
                metrics['Sharpe_Ratio'] = sharpe_ratio
            else:
                metrics['Sharpe_Ratio'] = 0
            
            # ìµœëŒ€ ë‚™í­
            cumulative = (1 + strategy_returns).cumprod()
            rolling_max = cumulative.expanding().max()
            drawdown = (cumulative - rolling_max) / rolling_max
            metrics['Max_Drawdown'] = float(drawdown.min())
            
            # ìŠ¹ë¥ 
            total_trades = len(strategy_returns[strategy_returns != 0])
            if total_trades > 0:
                winning_trades = len(strategy_returns[strategy_returns > 0])
                metrics['Win_Rate'] = winning_trades / total_trades
            else:
                metrics['Win_Rate'] = 0
            
            # ì†ìµë¹„
            gains = strategy_returns[strategy_returns > 0]
            losses = strategy_returns[strategy_returns < 0]
            
            avg_gain = gains.mean() if len(gains) > 0 else 0
            avg_loss = abs(losses.mean()) if len(losses) > 0 else 1
            
            metrics['Profit_Loss_Ratio'] = avg_gain / avg_loss if avg_loss != 0 else 0
            
            # ìœ„í—˜ ìˆ˜ì¤€ í‰ê°€
            risk_score = (abs(volatility) * 0.5 + abs(metrics['Max_Drawdown']) * 0.5)
            if risk_score < 0.15:
                metrics['Risk_Level'] = 'LOW'
            elif risk_score < 0.25:
                metrics['Risk_Level'] = 'MEDIUM'
            else:
                metrics['Risk_Level'] = 'HIGH'
            
            return metrics
            
        except Exception as e:
            st.error(f"ê³ ê¸‰ ì§€í‘œ ê³„ì‚° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return None

    def plot_model_comparison(self):
        """ëª¨ë¸ë³„ ì„±ëŠ¥ ë¹„êµ ì‹œê°í™”"""
        try:
            if not self.performance_metrics:
                st.warning("ì„±ëŠ¥ ì§€í‘œê°€ ê³„ì‚°ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë¨¼ì € analyze_signalsë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")
                return None, pd.DataFrame()

            # ì„±ëŠ¥ ì§€í‘œ ë°ì´í„°í”„ë ˆì„ ìƒì„±
            comparison_data = []
            for name, metrics in self.performance_metrics.items():
                if name not in self.predictions or self.predictions[name] is None:
                    continue
                    
                current_signal = self.predictions[name].iloc[-1] if len(self.predictions[name]) > 0 else 'HOLD'
                
                row_data = {
                    'Model': name,
                    'Current Signal': current_signal,
                    'Accuracy': f"{metrics.get('Win_Rate', 0)*100:.2f}%",
                    'Cumulative Return': f"{metrics.get('Cumulative_Return', 0)*100:.2f}%",
                    'Sharpe Ratio': f"{metrics.get('Sharpe_Ratio', 0):.2f}",
                    'Risk Level': metrics.get('Risk_Level', 'MEDIUM')
                }
                comparison_data.append(row_data)

            if not comparison_data:
                st.warning("í‘œì‹œí•  ëª¨ë¸ ë¹„êµ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return None, pd.DataFrame()

            comparison_df = pd.DataFrame(comparison_data)

            # ì‹œê°í™”
            fig = go.Figure()
            colors = {'BUY': 'green', 'SELL': 'red', 'HOLD': 'gray'}

            for signal in ['BUY', 'SELL', 'HOLD']:
                mask = comparison_df['Current Signal'] == signal
                if not any(mask):
                    continue

                fig.add_trace(go.Bar(
                    name=signal,
                    x=comparison_df[mask]['Model'],
                    y=[float(acc.strip('%')) for acc in comparison_df[mask]['Accuracy']],
                    marker_color=colors[signal]
                ))

            fig.update_layout(
                title='ëª¨ë¸ë³„ ì„±ëŠ¥ ë¹„êµ',
                xaxis_title='ëª¨ë¸',
                yaxis_title='ì •í™•ë„ (%)',
                barmode='group',
                showlegend=True,
                height=500
            )

            return fig, comparison_df

        except Exception as e:
            st.error(f"ëª¨ë¸ ë¹„êµ ì‹œê°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return None, pd.DataFrame()

class MarketAnalyzer:
    def __init__(self, data, benchmark_ticker='^GSPC'):  # S&P 500ì„ ê¸°ë³¸ ë²¤ì¹˜ë§ˆí¬ë¡œ ì‚¬ìš©
        self.data = data
        self.benchmark_ticker = benchmark_ticker
        self.benchmark_data = None
        self.market_regime = None
        self.correlation_matrix = None
        self.sector_performance = None
        
    def analyze_market_regime(self):
        """ì‹œì¥ êµ­ë©´ ë¶„ì„"""
        try:
            df = self.data.copy()
            
            # ë³€ë™ì„± ê³„ì‚°
            df['Volatility'] = df['Close'].pct_change().rolling(window=20).std() * np.sqrt(252)
            
            # ì¶”ì„¸ ê°•ë„ ê³„ì‚°
            df['Trend_Strength'] = abs(df['Close'].pct_change(20))
            
            # ì‹œì¥ êµ­ë©´ ë¶„ë¥˜
            df['Market_Regime'] = 'Neutral'
            
            # ê³ ë³€ë™ì„± & ê°•í•œ ìƒìŠ¹ì¶”ì„¸ = ê³¼ì—´
            mask_overheated = (df['Volatility'] > df['Volatility'].quantile(0.8)) & \
                            (df['Trend_Strength'] > df['Trend_Strength'].quantile(0.8))
            df.loc[mask_overheated, 'Market_Regime'] = 'Overheated'
            
            # ê³ ë³€ë™ì„± & ê°•í•œ í•˜ë½ì¶”ì„¸ = ê³µí¬
            mask_fear = (df['Volatility'] > df['Volatility'].quantile(0.8)) & \
                       (df['Trend_Strength'] < df['Trend_Strength'].quantile(0.2))
            df.loc[mask_fear, 'Market_Regime'] = 'Fear'
            
            # ì €ë³€ë™ì„± & ì™„ë§Œí•œ ìƒìŠ¹ì¶”ì„¸ = ì•ˆì •
            mask_stable = (df['Volatility'] < df['Volatility'].quantile(0.2)) & \
                         (df['Trend_Strength'] > df['Trend_Strength'].median())
            df.loc[mask_stable, 'Market_Regime'] = 'Stable'
            
            self.market_regime = df['Market_Regime']
            return df['Market_Regime']
            
        except Exception as e:
            st.error(f"ì‹œì¥ êµ­ë©´ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return None
    
    def calculate_market_correlation(self):
        """ì‹œì¥ê³¼ì˜ ìƒê´€ê´€ê³„ ë¶„ì„"""
        try:
            if self.benchmark_data is None:
                self.benchmark_data = fdr.DataReader(self.benchmark_ticker, 
                                                   self.data.index[0], 
                                                   self.data.index[-1])
            
            # ìˆ˜ìµë¥  ê³„ì‚°
            stock_returns = self.data['Close'].pct_change()
            market_returns = self.benchmark_data['Close'].pct_change()
            
            # ìƒê´€ê´€ê³„ ê³„ì‚°
            correlation = stock_returns.corr(market_returns)
            
            # ë² íƒ€ ê³„ì‚°
            covariance = stock_returns.cov(market_returns)
            market_variance = market_returns.var()
            beta = covariance / market_variance
            
            return {
                'Correlation': correlation,
                'Beta': beta
            }
            
        except Exception as e:
            st.error(f"ì‹œì¥ ìƒê´€ê´€ê³„ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return None
    
    def analyze_sector_performance(self, sector_tickers):
        """ì„¹í„° ì„±ê³¼ ë¶„ì„"""
        try:
            sector_data = {}
            for ticker in sector_tickers:
                sector_data[ticker] = fdr.DataReader(ticker, 
                                                   self.data.index[0], 
                                                   self.data.index[-1])
            
            # ì„¹í„°ë³„ ìˆ˜ìµë¥  ê³„ì‚°
            returns = {}
            for ticker, data in sector_data.items():
                returns[ticker] = (data['Close'][-1] / data['Close'][0] - 1) * 100
            
            self.sector_performance = returns
            return returns
            
        except Exception as e:
            st.error(f"ì„¹í„° ì„±ê³¼ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return None
    
    def calculate_risk_metrics(self):
        """ë¦¬ìŠ¤í¬ ë©”íŠ¸ë¦­ìŠ¤ ê³„ì‚°"""
        try:
            metrics = {}
            returns = self.data['Close'].pct_change().dropna()
            
            # ë³€ë™ì„±
            metrics['Volatility'] = returns.std() * np.sqrt(252)
            
            # ìƒ¤í”„ ë¹„ìœ¨
            risk_free_rate = 0.02  # ì—°ê°„ 2% ê°€ì •
            excess_returns = returns - risk_free_rate/252
            metrics['Sharpe_Ratio'] = np.sqrt(252) * returns.mean() / returns.std()
            
            # ìµœëŒ€ ë‚™í­
            cum_returns = (1 + returns).cumprod()
            rolling_max = cum_returns.expanding().max()
            drawdowns = (cum_returns - rolling_max) / rolling_max
            metrics['Max_Drawdown'] = drawdowns.min()
            
            # Value at Risk (95% ì‹ ë¢°ìˆ˜ì¤€)
            metrics['VaR_95'] = np.percentile(returns, 5)
            
            # Conditional VaR (Expected Shortfall)
            metrics['CVaR_95'] = returns[returns <= metrics['VaR_95']].mean()
            
            return metrics
            
        except Exception as e:
            st.error(f"ë¦¬ìŠ¤í¬ ë©”íŠ¸ë¦­ìŠ¤ ê³„ì‚° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return None
    
    def plot_market_analysis(self):
        """ì‹œì¥ ë¶„ì„ ê²°ê³¼ ì‹œê°í™”"""
        try:
            # ì‹œì¥ êµ­ë©´ ë¶„í¬ íŒŒì´ ì°¨íŠ¸
            regime_counts = self.market_regime.value_counts()
            fig1 = go.Figure(data=[go.Pie(labels=regime_counts.index, 
                                        values=regime_counts.values)])
            fig1.update_layout(title='ì‹œì¥ êµ­ë©´ ë¶„í¬')
            st.plotly_chart(fig1)
            
            # ë¦¬ìŠ¤í¬ ë©”íŠ¸ë¦­ìŠ¤ ë ˆì´ë” ì°¨íŠ¸
            risk_metrics = self.calculate_risk_metrics()
            if risk_metrics:
                fig2 = go.Figure(data=go.Scatterpolar(
                    r=[risk_metrics['Volatility'],
                       risk_metrics['Sharpe_Ratio'],
                       abs(risk_metrics['Max_Drawdown']),
                       abs(risk_metrics['VaR_95']),
                       abs(risk_metrics['CVaR_95'])],
                    theta=['ë³€ë™ì„±', 'ìƒ¤í”„ë¹„ìœ¨', 'ìµœëŒ€ë‚™í­', 'VaR', 'CVaR'],
                    fill='toself'
                ))
                fig2.update_layout(title='ë¦¬ìŠ¤í¬ í”„ë¡œíŒŒì¼')
                st.plotly_chart(fig2)
            
            # ì„¹í„° ì„±ê³¼ ë¹„êµ ë°” ì°¨íŠ¸
            if self.sector_performance:
                fig3 = go.Figure(data=[go.Bar(
                    x=list(self.sector_performance.keys()),
                    y=list(self.sector_performance.values())
                )])
                fig3.update_layout(title='ì„¹í„°ë³„ ì„±ê³¼ ë¹„êµ')
                st.plotly_chart(fig3)
            
        except Exception as e:
            st.error(f"ì‹œì¥ ë¶„ì„ ì‹œê°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

class BacktestSystem:
    def __init__(self, data, initial_capital=10000000):
        self.data = data
        self.initial_capital = initial_capital
        self.positions = pd.DataFrame(index=data.index).fillna(0)
        self.portfolio_value = pd.Series(index=data.index).fillna(0)
        self.trades = []
        
    def run_backtest(self, signals, commission=0.0015):
        """ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        try:
            # í¬íŠ¸í´ë¦¬ì˜¤ ì´ˆê¸°í™”
            capital = self.initial_capital
            position = 0
            self.trades = []
            
            for i in range(len(self.data)):
                date = self.data.index[i]
                close_price = self.data['Close'].iloc[i]
                
                # ë§¤ë§¤ ì‹ í˜¸ í™•ì¸
                if i > 0:  # ì²«ë‚ ì€ ì œì™¸
                    signal = signals['Final_Signal'].iloc[i-1]  # ì „ë‚  ì‹ í˜¸ë¡œ ì˜¤ëŠ˜ ë§¤ë§¤
                    
                    # ë§¤ìˆ˜ ì‹ í˜¸
                    if signal == 'BUY' and position == 0:
                        shares = int(capital * (1 - commission) / close_price)
                        cost = shares * close_price * (1 + commission)
                        if cost <= capital:
                            position = shares
                            capital -= cost
                            self.trades.append({
                                'Date': date,
                                'Type': 'BUY',
                                'Shares': shares,
                                'Price': close_price,
                                'Cost': cost
                            })
                    
                    # ë§¤ë„ ì‹ í˜¸
                    elif signal == 'SELL' and position > 0:
                        revenue = position * close_price * (1 - commission)
                        capital += revenue
                        self.trades.append({
                            'Date': date,
                            'Type': 'SELL',
                            'Shares': position,
                            'Price': close_price,
                            'Revenue': revenue
                        })
                        position = 0
                
                # í¬ì§€ì…˜ ë° í¬íŠ¸í´ë¦¬ì˜¤ ê°€ì¹˜ ê¸°ë¡
                self.positions.loc[date] = position
                self.portfolio_value.loc[date] = capital + (position * close_price)
            
            return self.calculate_backtest_metrics()
            
        except Exception as e:
            st.error(f"ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return None
    
    def calculate_backtest_metrics(self):
        """ë°±í…ŒìŠ¤íŠ¸ ì„±ê³¼ ì§€í‘œ ê³„ì‚°"""
        try:
            metrics = {}
            
            # ì¼ê°„ ìˆ˜ìµë¥ 
            daily_returns = self.portfolio_value.pct_change().dropna()
            
            # ì´ ìˆ˜ìµë¥ 
            metrics['Total_Return'] = (self.portfolio_value.iloc[-1] / self.initial_capital - 1) * 100
            
            # ì—°ê°„ ìˆ˜ìµë¥ 
            years = (self.data.index[-1] - self.data.index[0]).days / 365
            metrics['Annual_Return'] = ((1 + metrics['Total_Return']/100) ** (1/years) - 1) * 100
            
            # ë³€ë™ì„±
            metrics['Volatility'] = daily_returns.std() * np.sqrt(252) * 100
            
            # ìƒ¤í”„ ë¹„ìœ¨
            risk_free_rate = 0.02  # ì—°ê°„ 2% ê°€ì •
            excess_returns = daily_returns - risk_free_rate/252
            metrics['Sharpe_Ratio'] = np.sqrt(252) * excess_returns.mean() / daily_returns.std()
            
            # ìµœëŒ€ ë‚™í­
            cum_returns = (1 + daily_returns).cumprod()
            rolling_max = cum_returns.expanding().max()
            drawdowns = (cum_returns - rolling_max) / rolling_max
            metrics['Max_Drawdown'] = drawdowns.min() * 100
            
            # ìŠ¹ë¥ 
            winning_trades = len([t for t in self.trades if t['Type'] == 'SELL' and 
                                t['Revenue'] > t['Shares'] * self.trades[self.trades.index(t)-1]['Price']])
            total_trades = len([t for t in self.trades if t['Type'] == 'SELL'])
            metrics['Win_Rate'] = (winning_trades / total_trades * 100) if total_trades > 0 else 0
            
            # ì†ìµë¹„
            gains = [t['Revenue'] - t['Shares'] * self.trades[self.trades.index(t)-1]['Price'] 
                    for t in self.trades if t['Type'] == 'SELL']
            if gains:
                avg_gain = sum([g for g in gains if g > 0]) / len([g for g in gains if g > 0]) \
                    if len([g for g in gains if g > 0]) > 0 else 0
                avg_loss = abs(sum([g for g in gains if g < 0]) / len([g for g in gains if g < 0])) \
                    if len([g for g in gains if g < 0]) > 0 else 1
                metrics['Profit_Loss_Ratio'] = avg_gain / avg_loss if avg_loss != 0 else 0
            
            return metrics
            
        except Exception as e:
            st.error(f"ë°±í…ŒìŠ¤íŠ¸ ì§€í‘œ ê³„ì‚° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return None
    
    def plot_backtest_results(self):
        """ë°±í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì‹œê°í™”"""
        try:
            # í¬íŠ¸í´ë¦¬ì˜¤ ê°€ì¹˜ ë³€í™”
            fig1 = go.Figure()
            fig1.add_trace(go.Scatter(
                x=self.portfolio_value.index,
                y=self.portfolio_value.values,
                name='í¬íŠ¸í´ë¦¬ì˜¤ ê°€ì¹˜'
            ))
            fig1.update_layout(title='í¬íŠ¸í´ë¦¬ì˜¤ ê°€ì¹˜ ë³€í™”',
                             xaxis_title='ë‚ ì§œ',
                             yaxis_title='í¬íŠ¸í´ë¦¬ì˜¤ ê°€ì¹˜')
            st.plotly_chart(fig1)
            
            # ìˆ˜ìµë¥  ë¶„í¬
            daily_returns = self.portfolio_value.pct_change().dropna()
            fig2 = go.Figure(data=[go.Histogram(x=daily_returns, nbinsx=50)])
            fig2.update_layout(title='ì¼ê°„ ìˆ˜ìµë¥  ë¶„í¬',
                             xaxis_title='ìˆ˜ìµë¥ ',
                             yaxis_title='ë¹ˆë„')
            st.plotly_chart(fig2)
            
            # ë“œë¡œë‹¤ìš´ ì°¨íŠ¸
            cum_returns = (1 + daily_returns).cumprod()
            rolling_max = cum_returns.expanding().max()
            drawdowns = (cum_returns - rolling_max) / rolling_max
            
            fig3 = go.Figure()
            fig3.add_trace(go.Scatter(
                x=drawdowns.index,
                y=drawdowns.values * 100,
                fill='tozeroy',
                name='ë“œë¡œë‹¤ìš´'
            ))
            fig3.update_layout(title='ë“œë¡œë‹¤ìš´ ì°¨íŠ¸',
                             xaxis_title='ë‚ ì§œ',
                             yaxis_title='ë“œë¡œë‹¤ìš´ (%)')
            st.plotly_chart(fig3)
            
            # ì„±ê³¼ ì§€í‘œ í‘œì‹œ
            metrics = self.calculate_backtest_metrics()
            if metrics:
                st.write("### ë°±í…ŒìŠ¤íŠ¸ ì„±ê³¼ ì§€í‘œ")
                metrics_df = pd.DataFrame.from_dict(metrics, orient='index', columns=['ê°’'])
                st.dataframe(
                    metrics_df.style
                    .format({
                        'ê°’': '{:.2f}' if metrics_df.index != 'Profit_Loss_Ratio' else '{:.2f}:1'
                    })
                    .background_gradient(cmap='YlOrRd')
                )
            
        except Exception as e:
            st.error(f"ë°±í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì‹œê°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return None

# OpenAI API ì„¤ì •
from openai import OpenAI

def initialize_openai():
    """OpenAI API ì´ˆê¸°í™” ë° ì„¤ì •ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤."""
    try:
        api_key = st.secrets.get("OPENAI_API_KEY", None)
        if not api_key or api_key.strip() == "":
            st.warning("""
            OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë‹¤ìŒ ë‹¨ê³„ë¥¼ ë”°ë¼ ì„¤ì •í•´ì£¼ì„¸ìš”:
            1. '.streamlit/secrets.toml' íŒŒì¼ì„ ìƒì„±
            2. íŒŒì¼ì— 'OPENAI_API_KEY = "your-api-key"' ì¶”ê°€
            3. ì‹¤ì œ API í‚¤ë¡œ êµì²´
            
            í˜„ì¬ëŠ” ê¸°ë³¸ ë¶„ì„ ê¸°ëŠ¥ë§Œ ì œê³µë©ë‹ˆë‹¤.
            """)
            return None, None
        
        model = st.secrets.get("DEFAULT_MODEL", "gpt-4o-mini")
        client = OpenAI(api_key=api_key)
        return client, model
        
    except Exception as e:
        st.warning(f"""
        OpenAI API ì„¤ì • ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤:
        - ì—ëŸ¬: {str(e)}
        - '.streamlit/secrets.toml' íŒŒì¼ì´ ì˜¬ë°”ë¥´ê²Œ ì„¤ì •ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.
        
        í˜„ì¬ëŠ” ê¸°ë³¸ ë¶„ì„ ê¸°ëŠ¥ë§Œ ì œê³µë©ë‹ˆë‹¤.
        """)
        return None, None

# OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
client, model = initialize_openai()

def format_metrics(metrics: Dict[str, Any]) -> Dict[str, str]:
    """ì„±ëŠ¥ ì§€í‘œë¥¼ ë³´ê¸° ì¢‹ê²Œ í¬ë§·íŒ…í•©ë‹ˆë‹¤."""
    formatted = {}
    for key, value in metrics.items():
        if isinstance(value, float):
            if key in ['Win_Rate', 'Total_Return', 'Annual_Return']:
                formatted[key] = f"{value:.2f}%"
            elif key in ['Sharpe_Ratio', 'Profit_Loss_Ratio']:
                formatted[key] = f"{value:.2f}"
            else:
                formatted[key] = f"{value:.4f}"
        else:
            formatted[key] = str(value)
    return formatted

def analyze_model_performance(metrics: Dict[str, Any]) -> str:
    """ëª¨ë¸ ì„±ëŠ¥ì„ ë¶„ì„í•˜ê³  ì„¤ëª…ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    if not client or not model:
        # API í‚¤ê°€ ì—†ì„ ë•Œì˜ ê¸°ë³¸ ë¶„ì„ ë¡œì§
        formatted_metrics = format_metrics(metrics)
        analysis = []
        
        # ê¸°ë³¸ì ì¸ ì„±ëŠ¥ ë¶„ì„
        if 'Accuracy' in metrics:
            accuracy = float(formatted_metrics['Accuracy'].strip('%'))
            if accuracy > 70:
                analysis.append("ëª¨ë¸ì˜ ì •í™•ë„ê°€ ë§¤ìš° ë†’ìŠµë‹ˆë‹¤.")
            elif accuracy > 60:
                analysis.append("ëª¨ë¸ì˜ ì •í™•ë„ê°€ ì–‘í˜¸í•œ ìˆ˜ì¤€ì…ë‹ˆë‹¤.")
            else:
                analysis.append("ëª¨ë¸ì˜ ì •í™•ë„ê°€ ê°œì„ ì´ í•„ìš”í•œ ìˆ˜ì¤€ì…ë‹ˆë‹¤.")
        
        if 'Sharpe_Ratio' in metrics:
            sharpe = float(formatted_metrics['Sharpe_Ratio'])
            if sharpe > 1:
                analysis.append("ë¦¬ìŠ¤í¬ ëŒ€ë¹„ ìˆ˜ìµë¥ ì´ ìš°ìˆ˜í•©ë‹ˆë‹¤.")
            elif sharpe > 0:
                analysis.append("ë¦¬ìŠ¤í¬ ëŒ€ë¹„ ìˆ˜ìµë¥ ì´ ì–‘í˜¸í•©ë‹ˆë‹¤.")
            else:
                analysis.append("ë¦¬ìŠ¤í¬ ëŒ€ë¹„ ìˆ˜ìµë¥ ì´ ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        
        if 'Win_Rate' in metrics:
            win_rate = float(formatted_metrics['Win_Rate'].strip('%'))
            if win_rate > 60:
                analysis.append("ìŠ¹ë¥ ì´ ë§¤ìš° ë†’ì€ ìˆ˜ì¤€ì…ë‹ˆë‹¤.")
            elif win_rate > 50:
                analysis.append("ìŠ¹ë¥ ì´ ì–‘í˜¸í•œ ìˆ˜ì¤€ì…ë‹ˆë‹¤.")
            else:
                analysis.append("ìŠ¹ë¥ ì´ ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        
        # íˆ¬ìì ì£¼ì˜ì‚¬í•­
        analysis.append("\níˆ¬ì ì‹œ ì£¼ì˜ì‚¬í•­:")
        analysis.append("- ê³¼ê±° ì„±ê³¼ê°€ ë¯¸ë˜ ìˆ˜ìµì„ ë³´ì¥í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        analysis.append("- ë¶„ì‚° íˆ¬ìë¥¼ í†µí•œ ë¦¬ìŠ¤í¬ ê´€ë¦¬ê°€ ì¤‘ìš”í•©ë‹ˆë‹¤.")
        analysis.append("- ì •ê¸°ì ì¸ í¬íŠ¸í´ë¦¬ì˜¤ ë¦¬ë°¸ëŸ°ì‹±ì„ ê³ ë ¤í•˜ì„¸ìš”.")
        
        return "\n".join(analysis)
    
    try:
        # ë©”íŠ¸ë¦­ìŠ¤ë¥¼ í¬ë§·íŒ…
        formatted_metrics = format_metrics(metrics)
        metrics_str = "\n".join([f"{k}: {v}" for k, v in formatted_metrics.items()])
        
        # GPT-4ì— ì „ì†¡í•  í”„ë¡¬í”„íŠ¸ ì‘ì„±
        prompt = f"""
        ë‹¤ìŒì€ ê¸ˆìœµ ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì˜ ì„±ëŠ¥ ì§€í‘œì…ë‹ˆë‹¤:
        {metrics_str}
        
        ì´ ì„±ëŠ¥ ì§€í‘œë“¤ì„ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒ ì‚¬í•­ë“¤ì„ í¬í•¨í•˜ì—¬ ì „ë¬¸ê°€ì ì¸ ë¶„ì„ì„ ì œê³µí•´ì£¼ì„¸ìš”:
        1. ëª¨ë¸ì˜ ì „ë°˜ì ì¸ ì„±ëŠ¥ í‰ê°€
        2. ê°•ì ê³¼ ì•½ì 
        3. ì‹¤ì „ íŠ¸ë ˆì´ë”©ì—ì„œì˜ í™œìš© ê°€ëŠ¥ì„±
        4. ê°œì„ ì´ í•„ìš”í•œ ë¶€ë¶„
        5. íˆ¬ììë“¤ì´ ì£¼ì˜í•´ì•¼ í•  ì 
        
        ë¶„ì„ì€ ì „ë¬¸ì ì´ë©´ì„œë„ ì´í•´í•˜ê¸° ì‰½ê²Œ ì‘ì„±í•´ì£¼ì„¸ìš”.
        """
        
        # GPT API í˜¸ì¶œ
        max_tokens = st.secrets.get("MAX_TOKENS", 1000)
        temperature = st.secrets.get("TEMPERATURE", 0.7)
        
        response = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ ê¸ˆìœµ ë¨¸ì‹ ëŸ¬ë‹ ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
                {"role": "user", "content": prompt}
            ],
            temperature=temperature,
            max_tokens=max_tokens
        )
        
        return response.choices[0].message.content
        
    except Exception as e:
        st.error(f"ëª¨ë¸ ì„±ëŠ¥ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
        return "ëª¨ë¸ ì„±ëŠ¥ ë¶„ì„ì„ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ ì§€í‘œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”."

if st.sidebar.button("ë¶„ì„ ì‹œì‘"):
    stock_data = get_stock_data(ticker, start_date, end_date)
    if stock_data is not None:
        with st.spinner("ë°ì´í„° ë¶„ì„ ì¤‘..."):
            try:
                tech_analyzer = TechnicalAnalyzer(stock_data)
                prob_analyzer = ProbabilisticAnalyzer(tech_analyzer.data)
                if prob_analyzer.train_models():
                    st.subheader("ğŸ“Š ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ ë¶„ì„")
                    prob_analyzer.compare_models()
                    st.subheader("ğŸ“ˆ íŠ¹ì„± ì¤‘ìš”ë„ ë¶„ì„")
                    prob_analyzer.plot_feature_importance()
                    st.subheader("ğŸ“‰ ROC ê³¡ì„  ë¶„ì„")
                    prob_analyzer.plot_roc_curves()
                    st.subheader("ğŸ¤– ëª¨ë¸ë³„ ë§¤ë§¤ ì‹ í˜¸ ë¶„ì„")
                    
                    try:
                        model_analyzer = ModelSignalAnalyzer(prob_analyzer.models, tech_analyzer.data, prob_analyzer.predictions)
                        signals_result = model_analyzer.analyze_signals()
                        
                        if signals_result is not None:
                            try:
                                fig, matrix_df = model_analyzer.plot_model_comparison()
                                if fig is not None and not matrix_df.empty:
                                    st.write("### ëª¨ë¸ë³„ ë§¤ë§¤ ì‹ í˜¸ í™•ë¥ ")
                                    try:
                                        # ê¸°ì¡´ ë°ì´í„°í”„ë ˆì„ í‘œì‹œ
                                        st.dataframe(
                                            matrix_df.style.apply(
                                                lambda x: [
                                                    'background-color: #e6ffe6' if v == 'BUY'
                                                    else 'background-color: #ffe6e6' if v == 'SELL'
                                                    else 'background-color: #f2f2f2'
                                                    for v in x
                                                ],
                                                subset=['Current Signal']
                                            )
                                        )
                                        st.plotly_chart(fig)
                                        
                                        # ê° ëª¨ë¸ë³„ ìƒì„¸ ë¶„ì„
                                        st.write("### ëª¨ë¸ë³„ ìƒì„¸ ë¶„ì„")
                                        for name, metrics in self.performance_metrics.items():
                                            with st.expander(f"{name} ëª¨ë¸ ìƒì„¸ ë¶„ì„"):
                                                # ê¸°ë³¸ ë©”íŠ¸ë¦­ìŠ¤ í‘œì‹œ
                                                st.write("#### ê¸°ë³¸ ì„±ëŠ¥ ì§€í‘œ")
                                                metrics_df = pd.DataFrame(
                                                    metrics.items(),
                                                    columns=['ì§€í‘œ', 'ê°’']
                                                ).set_index('ì§€í‘œ')
                                                st.dataframe(metrics_df)
                                                
                                                # GPT-4ë¥¼ ì‚¬ìš©í•œ ìƒì„¸ ë¶„ì„
                                                st.write("#### AI ì „ë¬¸ê°€ ë¶„ì„")
                                                analysis = analyze_model_performance(metrics)
                                                st.markdown(analysis)
                                    except Exception as e:
                                        st.error(f"ë§¤ë§¤ ì‹ í˜¸ ì‹œê°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                                else:
                                    st.warning("ëª¨ë¸ ë¹„êµ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
                            except Exception as e:
                                st.error(f"ëª¨ë¸ ë¹„êµ ì‹œê°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                        else:
                            st.warning("ë§¤ë§¤ ì‹ í˜¸ ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
                    except Exception as e:
                        st.error(f"ë§¤ë§¤ ì‹ í˜¸ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                    
                    # íšŒê·€ ë¶„ì„ ì‹œê°í™”
                    try:
                        prob_analyzer.plot_regression_analysis()
                    except Exception as e:
                        st.error(f"íšŒê·€ ë¶„ì„ ì‹œê°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            except Exception as e:
                st.error(f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
    else:
        st.error("ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ”ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. í‹°ì»¤ ì‹¬ë³¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")

