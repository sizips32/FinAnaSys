import streamlit as st
import FinanceDataReader as fdr
import pandas as pd
import numpy as np
from pypfopt import (
    EfficientFrontier, risk_models, expected_returns, HRPOpt, CLA
)
from arch import arch_model
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
import time

warnings.simplefilter(action='ignore', category=FutureWarning)

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    layout="wide",
    page_title="Advanced Portfolio Analytics",
    page_icon="ğŸ“ˆ"
)

# í•œê¸€ í°íŠ¸ ì„¤ì •
plt.rcParams['font.family'] = 'AppleGothic'  # Mac
plt.rcParams['axes.unicode_minus'] = False  # ë§ˆì´ë„ˆìŠ¤ ê¸°í˜¸ ê¹¨ì§ ë°©ì§€

# CSS ìŠ¤íƒ€ì¼ ì ìš©
st.markdown("""
<style>
    @import url('https://fonts.googleapis.com/css2?family=Noto+Sans+KR:wght@400;700&display=swap');
    
    html, body, [class*="css"] {
        font-family: 'Noto Sans KR', sans-serif;
    }
    
    .stMarkdown {
        font-family: 'Noto Sans KR', sans-serif;
    }
</style>
""", unsafe_allow_html=True)

# ì‚¬ì´ë“œë°” ì„¤ì •
st.sidebar.title("í¬íŠ¸í´ë¦¬ì˜¤ ë¶„ì„ ì„¤ì • ğŸ› ï¸")

# ê¸°ë³¸ ì…ë ¥ íŒŒë¼ë¯¸í„°
tickers = st.sidebar.text_input(
    "ì¢…ëª© ì½”ë“œ ì…ë ¥ (ì‰¼í‘œë¡œ êµ¬ë¶„) ğŸ“",
    "005930, 035420, 051910, 035720"  # ê¸°ë³¸ ì˜ˆì‹œ ì¢…ëª© (ì‚¼ì„±ì „ì, NAVER, LGí™”í•™,ì¹´ì¹´ì˜¤)
)
start_date = st.sidebar.date_input("Start Date", value=pd.to_datetime("2020-01-01"))
end_date = st.sidebar.date_input("End Date", value=pd.Timestamp.now().date())

# ìµœì í™” ì„¤ì •
st.sidebar.markdown("### í¬íŠ¸í´ë¦¬ì˜¤ ìµœì í™” ì„¤ì • âš™ï¸")
optimization_method = st.sidebar.selectbox(
    "ìµœì í™” ë°©ë²• ì„ íƒ",
    [
        "ìµœëŒ€ ìƒ¤í”„ ì§€ìˆ˜ (Maximum Sharpe Ratio) âš¡", 
        "ìµœì†Œ ë³€ë™ì„± (Minimum Volatility) ğŸ›¡ï¸", 
        "ë¦¬ìŠ¤í¬ ê· í˜• (Risk Parity) âš–ï¸"
    ]
)

rebalance_period = st.sidebar.selectbox(
    "Rebalancing Frequency",
    ["Monthly", "Quarterly", "Semi-Annually", "Annually"],
    help="Select the rebalancing frequency for the portfolio."
)

# ì‚¬ì´ë“œë°” ì„¤ì • ë¶€ë¶„ì— ì¶”ê°€
st.sidebar.markdown("### ë™ì  í—¤ì§€ ì„¤ì • ğŸ›¡ï¸")
hedge_params = st.sidebar.expander("í—¤ì§€ íŒŒë¼ë¯¸í„° ì„¤ì •", expanded=False)

with hedge_params:
    # ê¸°ë³¸ ì„ê³„ê°’
    base_threshold = st.slider(
        "ê¸°ë³¸ ë³€ë™ì„± ì„ê³„ê°’ (%)",
        min_value=10.0,
        max_value=50.0,
        value=15.0,
        step=1.0,
        format="%.1f%%"
    )
    
    # í—¤ì§€ ê°•ë„
    hedge_intensity = st.slider(
        "í—¤ì§€ ê°•ë„ ì¡°ì ˆ",
        min_value=0.1,
        max_value=2.0,
        value=1.0,
        step=0.1,
        help="1.0 = ê¸°ë³¸, 2.0 = 2ë°° ê°•í•œ í—¤ì§€"
    )
    
    # ìµœëŒ€ í—¤ì§€ ë¹„ìœ¨
    max_hedge_ratio = st.slider(
        "ìµœëŒ€ í—¤ì§€ ë¹„ìœ¨",
        min_value=0.1,
        max_value=1.0,
        value=0.7,
        step=0.1,
        help="í—¤ì§€ ê°€ëŠ¥ ìµœëŒ€ í¬íŠ¸í´ë¦¬ì˜¤ ë¹„ì¤‘"
    )

# ë¶„ì„ ì‹¤í–‰ ë²„íŠ¼
run_analysis = st.sidebar.button("Run Analysis", use_container_width=True)

# íƒ­ ìƒì„±
tab1, tab2, tab3, tab4 = st.tabs([
    "í¬íŠ¸í´ë¦¬ì˜¤ ìµœì í™” ë° ë¦¬ìŠ¤í¬ ë¶„ì„ ğŸ“Š", 
    "ë¦¬ë°¸ëŸ°ì‹± ì‹œë®¬ë ˆì´ì…˜ ğŸ”„",
    "ìŠ¤íŠ¸ë ˆìŠ¤ í…ŒìŠ¤íŠ¸ ğŸ§ª",
    "ë™ì  í—¤ì§€ ì „ëµ ğŸ›¡ï¸"
])

# í¬íŠ¸í´ë¦¬ì˜¤ ìµœì í™” ê²°ê³¼ ì„¤ëª…
method_descriptions = {
    "ìµœëŒ€ ìƒ¤í”„ ì§€ìˆ˜ (Maximum Sharpe Ratio) âš¡": """
    ### ğŸ“ˆ ìµœëŒ€ ìƒ¤í”„ ì§€ìˆ˜ ì „ëµ
    **ìœ„í—˜ ëŒ€ë¹„ ìˆ˜ìµë¥ ì„ ìµœëŒ€í™”** í•˜ëŠ” í¬íŠ¸í´ë¦¬ì˜¤ êµ¬ì„±
    - ì¥ì : ë†’ì€ ìœ„í—˜ ì¡°ì • ìˆ˜ìµë¥  ê¸°ëŒ€
    - ë‹¨ì : íŠ¹ì • ìì‚°ì— ì§‘ì¤‘ë  ìˆ˜ ìˆìŒ
    - ì í•© ìƒí™©: ì‹œì¥ ì˜ˆì¸¡ì´ ë¹„êµì  ëª…í™•í•  ë•Œ
    """,
    
    "ìµœì†Œ ë³€ë™ì„± (Minimum Volatility) ğŸ›¡ï¸": """
    ### ğŸ“‰ ìµœì†Œ ë³€ë™ì„± ì „ëµ 
    **í¬íŠ¸í´ë¦¬ì˜¤ ë³€ë™ì„±ì„ ìµœì†Œí™”** í•˜ëŠ” ì•ˆì •ì  êµ¬ì„±
    - ì¥ì : ì‹œì¥ ë³€ë™ì„±ì— ëœ ë¯¼ê°
    - ë‹¨ì : ìˆ˜ìµë¥  ìƒëŒ€ì ìœ¼ë¡œ ë‚®ì„ ìˆ˜ ìˆìŒ
    - ì í•© ìƒí™©: ì‹œì¥ ë¶ˆí™•ì‹¤ì„± ë†’ì„ ë•Œ
    """,
    
    "ë¦¬ìŠ¤í¬ ê· í˜• (Risk Parity) âš–ï¸": """
    ### âš–ï¸ ë¦¬ìŠ¤í¬ ê· í˜• ì „ëµ
    **ëª¨ë“  ìì‚°ì˜ ë¦¬ìŠ¤í¬ ê¸°ì—¬ë„ë¥¼ ê· ë“±í•˜ê²Œ** ë¶„ë°°
    - ì¥ì : ìš°ìˆ˜í•œ ë¦¬ìŠ¤í¬ ë¶„ì‚° íš¨ê³¼
    - ë‹¨ì : ê³„ì‚° ë³µì¡ë„ ë†’ìŒ
    - ì í•© ìƒí™©: ìì‚° ê°„ ìƒê´€ê´€ê³„ ë‚®ì„ ë•Œ
    """
}

# ìœ„í—˜ ì§€í‘œ ì„¤ëª…
risk_metric_explanation = """
### ğŸ“Œ ì£¼ìš” ìœ„í—˜ ì§€í‘œ ì„¤ëª…
| ì§€í‘œ | ì„¤ëª… | í•´ì„ ê¸°ì¤€ |
|------|------|------|
| **ë³€ë™ì„±** | ìˆ˜ìµë¥ ì˜ í‘œì¤€í¸ì°¨(ì—°ìœ¨í™”) | ë‚®ì„ìˆ˜ë¡ ì•ˆì •ì  |
| **ìƒ¤í”„ ì§€ìˆ˜** | ìœ„í—˜ ë‹¨ìœ„ë‹¹ ì´ˆê³¼ìˆ˜ìµ | ë†’ì„ìˆ˜ë¡ ìš°ìˆ˜ |
| **ì†Œë¥´í‹°ë…¸** | í•˜ë°© ë³€ë™ì„± ê³ ë ¤í•œ ìœ„í—˜ì¡°ì • ìˆ˜ìµ | ë†’ì„ìˆ˜ë¡ ìš°ìˆ˜ |
| **MDD** | ìµœëŒ€ ë‚™í­(ì—­ëŒ€ ìµœê³ ì  ëŒ€ë¹„ ìµœì €ì ) | ë‚®ì„ìˆ˜ë¡ ì•ˆì „ |
| **VaR 95%** | 95% ì‹ ë¢°êµ¬ê°„ ìµœëŒ€ ì˜ˆìƒ ì†ì‹¤ | ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ |
| **CVaR 95%** | VaR ì´ˆê³¼ì‹œ í‰ê·  ì†ì‹¤ì•¡ | ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ |
"""

# ìŠ¤íŠ¸ë ˆìŠ¤ í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤
stress_scenarios = {
    "ì‹œì¥ í­ë½ ğŸ“‰": -0.20,
    "ê²½ê¸° ì¹¨ì²´ ğŸ’¸": -0.30,
    "ë³´í†µ í•˜ë½ ğŸ“‰": -0.10,
    "í…Œí¬ ë²„ë¸” ğŸ’£": -0.25,
    "ê¸ˆìœµ ìœ„ê¸° ğŸšï¸": -0.35
}

# ë™ì  í—¤ì§€ ì „ëµ ì„¤ëª…
hedge_strategy_explanation = """
### ğŸ›¡ï¸ ë™ì  í—¤ì§€ ì „ëµ ì›ë¦¬
1. **ì‹¤ì‹œê°„ ë³€ë™ì„± ëª¨ë‹ˆí„°ë§**  
   â†’ GARCH ëª¨ë¸ë¡œ ì¼ì¼ ë³€ë™ì„± ì¶”ì • ğŸ“ˆ
2. **í—¤ì§€ ë¹„ìœ¨ ìë™ ì¡°ì •**  
   â†’ ë³€ë™ì„± ì„ê³„ì¹˜ ì´ˆê³¼ì‹œ í—¤ì§€ ê°•í™” âš–ï¸
3. **ë¦¬ìŠ¤í¬ ë…¸ì¶œ ì œí•œ**  
   â†’ ê·¹ë‹¨ì  ì‹œì¥ ìƒí™©ì—ì„œ ì†ì‹¤ ìµœì†Œí™” ğŸ›‘
"""

def fetch_data(tickers_list, start_date, end_date):
    """
    FinanceDataReaderë¥¼ ì‚¬ìš©í•˜ì—¬ ì£¼ê°€ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜
    
    Parameters:
    tickers_list (list): ì¢…ëª© ì½”ë“œ ë¦¬ìŠ¤íŠ¸
    start_date (datetime): ì‹œì‘ì¼
    end_date (datetime): ì¢…ë£Œì¼
    
    Returns:
    tuple: (prices_df, returns_df) - ê°€ê²© ë°ì´í„°í”„ë ˆì„ê³¼ ìˆ˜ìµë¥  ë°ì´í„°í”„ë ˆì„
    """
    try:
        if not tickers_list or len(tickers_list) == 0:
            raise ValueError("ì¢…ëª© ì½”ë“œë¥¼ í•˜ë‚˜ ì´ìƒ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            
        valid_tickers = []
        data_frames = []
        
        # KRX ì¢…ëª© ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
        krx = fdr.StockListing('KRX')
        
        # ì»¬ëŸ¼ëª… í™•ì¸ ë° ì²˜ë¦¬
        symbol_column = None
        name_column = None
        
        if 'Symbol' in krx.columns:
            symbol_column = 'Symbol'
            name_column = 'Name'
        elif 'Code' in krx.columns:
            symbol_column = 'Code'
            name_column = 'Name'
        elif 'ì¢…ëª©ì½”ë“œ' in krx.columns:
            symbol_column = 'ì¢…ëª©ì½”ë“œ'
            name_column = 'ì¢…ëª©ëª…'
            
        if symbol_column is None:
            raise ValueError("ì£¼ì‹ ì‹œì¥ ë°ì´í„° í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        
        for ticker in tickers_list:
            t = ticker.strip().upper()
            try:
                # í•œêµ­ ì£¼ì‹ì¸ì§€ í™•ì¸
                is_korean = t in krx[symbol_column].values
                
                if is_korean:
                    # í•œêµ­ ì£¼ì‹ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
                    temp_data = fdr.DataReader(t, start_date, end_date)
                    company_name = krx[krx[symbol_column] == t][name_column].iloc[0]
                else:
                    # ë¯¸êµ­ ì£¼ì‹ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
                    temp_data = fdr.DataReader(t, start_date, end_date)
                    company_name = t  # ë¯¸êµ­ ì£¼ì‹ì€ ì‹¬ë³¼ì„ íšŒì‚¬ëª…ìœ¼ë¡œ ì‚¬ìš©
                
                if temp_data is not None and not temp_data.empty:
                    if 'Close' in temp_data.columns:
                        close_series = temp_data['Close'].rename(f"{company_name} ({t})")
                        data_frames.append(close_series)
                        valid_tickers.append(t)
                    else:
                        st.warning(f"{t}ì˜ ì¢…ê°€ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    st.warning(f"{t}ì˜ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    
            except Exception as e:
                st.warning(f"{t} ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
        
        if not valid_tickers:
            raise ValueError("ìœ íš¨í•œ ì¢…ëª© ì½”ë“œê°€ ì—†ìŠµë‹ˆë‹¤.")
            
        data = pd.concat(data_frames, axis=1)
        data = data.ffill().bfill().dropna(how='all', axis=1)
        
        if data.empty:
            raise ValueError("ì²˜ë¦¬ í›„ ìœ íš¨í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            
        returns = data.pct_change().dropna()
        
        if len(returns) < 252:
            st.warning("ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤ (ìµœì†Œ 1ë…„ í•„ìš”)")
            return None, None
            
        return data, returns
        
    except Exception as e:
        st.error(f"ğŸš¨ ë°ì´í„° ì˜¤ë¥˜: {str(e)}")
        st.error("ë¬¸ì œ í•´ê²° ë°©ë²•:\n1. ì¸í„°ë„· ì—°ê²° í™•ì¸\n2. ì¢…ëª© ì½”ë“œ í™•ì¸\n3. ë‚ ì§œ ë²”ìœ„ ì¡°ì •")
        return None, None

def calculate_risk_metrics(returns, weights=None):
    """ìœ„í—˜ ì§€í‘œ ê³„ì‚°"""
    # Seriesì¸ ê²½ìš° ë°”ë¡œ ì²˜ë¦¬
    if isinstance(returns, pd.Series):
        portfolio_returns = returns
    # DataFrameì¸ ê²½ìš° ê°€ì¤‘ì¹˜ ì ìš©
    else:
        if weights is None:
            weights = np.ones(len(returns.columns)) / len(returns.columns)
        portfolio_returns = returns.dot(weights)
    
    metrics = {
        'Volatility': portfolio_returns.std() * np.sqrt(252),
        'Sharpe': calculate_sharpe_ratio(portfolio_returns),
        'Sortino': calculate_sortino_ratio(portfolio_returns),
        'MDD': calculate_mdd(portfolio_returns),
        'VaR_95': calculate_var(portfolio_returns),
        'CVaR_95': calculate_cvar(portfolio_returns)
    }
    return metrics

def calculate_sharpe_ratio(returns, risk_free_rate=0.02):
    """ìƒ¤í”„ ë¹„ìœ¨ ê³„ì‚°"""
    excess_returns = returns - risk_free_rate/252
    return np.sqrt(252) * excess_returns.mean() / returns.std()

def calculate_sortino_ratio(returns, risk_free_rate=0.02):
    """ì†Œë¥´í‹°ë…¸ ë¹„ìœ¨ ê³„ì‚°"""
    excess_returns = returns - risk_free_rate/252
    downside_returns = returns[returns < 0]
    return np.sqrt(252) * excess_returns.mean() / downside_returns.std()

def calculate_mdd(returns):
    """ìµœëŒ€ ë‚™í­(MDD) ê³„ì‚°"""
    cumulative = (1 + returns).cumprod()
    running_max = cumulative.expanding().max()
    drawdown = (cumulative - running_max) / running_max
    return drawdown.min()

def calculate_var(returns, confidence_level=0.95):
    """VaR(Value at Risk) ê³„ì‚°"""
    return np.percentile(returns, (1-confidence_level)*100)

def calculate_cvar(returns, confidence_level=0.95):
    """CVaR(Conditional Value at Risk) ê³„ì‚°"""
    var = calculate_var(returns, confidence_level)
    return returns[returns <= var].mean()

def run_stress_test(returns, scenarios):
    """ìŠ¤íŠ¸ë ˆìŠ¤ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    results = {}
    for scenario_name, shock in scenarios.items():
        shocked_returns = returns * (1 + shock)
        metrics = calculate_risk_metrics(shocked_returns)
        results[scenario_name] = metrics
    return results

# í—¤ì§€ ì‹œë®¬ë ˆì´ì…˜ í•¨ìˆ˜ì— ìºì‹± ì¶”ê°€
@st.cache_data
def prepare_hedge_data(returns):
    """í—¤ì§€ ê³„ì‚°ì— í•„ìš”í•œ ê¸°ë³¸ ë°ì´í„° ì¤€ë¹„"""
    portfolio_returns = returns.mean(axis=1)
    window_size = 63
    return portfolio_returns, window_size

def simulate_dynamic_hedge(_portfolio_returns, window_size, params):
    """í™•ì¥ëœ í—¤ì§€ íŒŒë¼ë¯¸í„° ì ìš©"""
    hedge_ratio = []
    
    base_threshold = params['base_threshold']
    hedge_intensity = params['intensity']
    max_ratio = params['max_ratio']
    
    for i in range(window_size, len(_portfolio_returns)):
        # ë³€ë™ì„± ì˜ˆì¸¡
        train_data = _portfolio_returns.iloc[i-window_size:i]
        model = arch_model(train_data, vol='Garch', p=1, q=1, dist='normal')
        res = model.fit(update_freq=0, disp='off')
        forecast = res.forecast(horizon=21)
        predicted_vol = np.sqrt(forecast.variance.iloc[-1, -1]) * np.sqrt(252)
        
        # í—¤ì§€ ë¹„ìœ¨ ê³„ì‚° í™•ì¥
        if predicted_vol > base_threshold:
            excess_vol = predicted_vol - base_threshold
            ratio = min(max_ratio, (excess_vol / base_threshold) * hedge_intensity)
        else:
            ratio = 0.0
            
        hedge_ratio.append(ratio)
    
    return hedge_ratio

def fetch_exchange_rate():
    """ë‹¬ëŸ¬/ì› í™˜ìœ¨ ì •ë³´ ê°€ì ¸ì˜¤ê¸°"""
    try:
        usd_krw = fdr.DataReader("USDKRW=X", start_date, end_date)['Close'].iloc[-1]
        return usd_krw
    except Exception as e:
        st.warning("í™˜ìœ¨ ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ”ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ê¸°ë³¸ê°’ 1,300ì›ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        return 1300.0

def run_rebalancing_simulation():
    # ë¦¬ë°¸ëŸ°ì‹± ì£¼ê¸° ë§¤í•‘ ë¡œì§ ì¶”ê°€
    freq_mapping = {
        "Monthly": 'M',
        "Quarterly": 'Q',
        "Semi-Annually": '6M',
        "Annually": 'A'
    }
    
    try:
        rebalance_dates = pd.date_range(
            start=dates[0],
            end=dates[-1],
            freq=freq_mapping[rebalance_period]
        )
        
        # ... ê¸°ì¡´ ì½”ë“œ ...
        
    except KeyError:
        st.error("ì˜ëª»ëœ ë¦¬ë°¸ëŸ°ì‹± ì£¼ê¸° ì„¤ì •ì…ë‹ˆë‹¤")
    except Exception as e:
        st.error(f"ë¦¬ë°¸ëŸ°ì‹± ì‹œë®¬ë ˆì´ì…˜ ì‹¤íŒ¨: {str(e)}")
        st.error("ë¬¸ì œ ë°œìƒ ì‹œ ì²´í¬ì‚¬í•­:\n"
                 "1. ë¶„ì„ ê¸°ê°„ì´ ë¦¬ë°¸ëŸ°ì‹± ì£¼ê¸°ë³´ë‹¤ ê¸´ì§€ í™•ì¸\n"
                 "2. í¬íŠ¸í´ë¦¬ì˜¤ ê°€ì¤‘ì¹˜ í•©ê³„ ê²€ì¦\n"
                 "3. ìˆ˜ìµë¥  ë°ì´í„° ì •í™•ì„± í™•ì¸")

# ë©”ì¸ ì‹¤í–‰ ë¶€ë¶„
if run_analysis:
    tickers_list = [t.strip().upper() for t in tickers.split(",")]
    data, returns = fetch_data(tickers_list, start_date, end_date)
    
    if data is not None and returns is not None:
        try:
            with tab1:
                st.header("Portfolio Optimization & Risk Analysis")
                
                # ê¸°ë³¸ ì •ë³´ í‘œì‹œ
                st.subheader("Basic Portfolio Information")
                col1, col2 = st.columns(2)
                
                with col1:
                    # ìˆ˜ìµë¥  íˆíŠ¸ë§µ
                    corr_matrix = returns.corr()
                    fig_corr = plt.figure(figsize=(10, 6))
                    sns.heatmap(
                        corr_matrix, 
                        annot=True, 
                        cmap='coolwarm', 
                        center=0,
                        fmt='.2f'
                    )
                    plt.title("Asset Correlation")
                    st.pyplot(fig_corr)
                
                with col2:
                    # ê°œë³„ ìì‚° ì„±ê³¼
                    cumulative_returns = (1 + returns).cumprod()
                    st.line_chart(cumulative_returns)
                    st.caption("Cumulative Returns of Individual Assets")
                
                # í¬íŠ¸í´ë¦¬ì˜¤ ìµœì í™”
                st.subheader(f"Portfolio Optimization Result ({optimization_method})")
                
                # ìµœì í™” ê²°ê³¼ ì €ì¥
                global weights, performance
                if optimization_method == "ìµœëŒ€ ìƒ¤í”„ ì§€ìˆ˜ (Maximum Sharpe Ratio) âš¡":
                    ef = EfficientFrontier(expected_returns.mean_historical_return(data), risk_models.sample_cov(data))
                    ef.max_sharpe()
                    weights = ef.clean_weights()
                    performance = ef.portfolio_performance()
                    method_description = method_descriptions["ìµœëŒ€ ìƒ¤í”„ ì§€ìˆ˜ (Maximum Sharpe Ratio) âš¡"]
                elif optimization_method == "ìµœì†Œ ë³€ë™ì„± (Minimum Volatility) ğŸ›¡ï¸":
                    ef = EfficientFrontier(expected_returns.mean_historical_return(data), risk_models.sample_cov(data))
                    ef.min_volatility()
                    weights = ef.clean_weights()
                    performance = ef.portfolio_performance()
                    method_description = method_descriptions["ìµœì†Œ ë³€ë™ì„± (Minimum Volatility) ğŸ›¡ï¸"]
                elif optimization_method == "ë¦¬ìŠ¤í¬ ê· í˜• (Risk Parity) âš–ï¸":
                    try:
                        # ê³µë¶„ì‚° í–‰ë ¬ ì–‘ì •ì¹˜(positive definite) ê²€ì¦
                        S = risk_models.fix_nonpositive_semidefinite(risk_models.sample_cov(data))
                        
                        # ë°ì´í„° ì „ì²˜ë¦¬
                        clean_returns = returns.copy()
                        
                        # ë¬´í•œê°’ê³¼ NaN ì²˜ë¦¬
                        clean_returns = clean_returns.replace([np.inf, -np.inf], np.nan)
                        clean_returns = clean_returns.fillna(method='ffill').fillna(method='bfill')
                        
                        # ê·¹ë‹¨ê°’ ì²˜ë¦¬ (1~99 percentileë¡œ ì œí•œ)
                        for col in clean_returns.columns:
                            upper = np.percentile(clean_returns[col].dropna(), 99)
                            lower = np.percentile(clean_returns[col].dropna(), 1)
                            clean_returns[col] = clean_returns[col].clip(lower, upper)
                        
                        # ë‚¨ì€ NaN ì²˜ë¦¬
                        if clean_returns.isnull().any().any():
                            clean_returns = clean_returns.fillna(clean_returns.mean())
                        
                        # ê³µë¶„ì‚° í–‰ë ¬ ê³„ì‚° ë° ê²€ì¦
                        cov_matrix = clean_returns.cov()
                        if not np.isfinite(cov_matrix.values).all():
                            raise ValueError("ê³µë¶„ì‚° í–‰ë ¬ì— ë¬´í•œê°’ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
                        
                        # ìƒê´€ê´€ê³„ í–‰ë ¬ ê²€ì¦
                        corr_matrix = clean_returns.corr()
                        if not np.isfinite(corr_matrix.values).all():
                            raise ValueError("ìƒê´€ê´€ê³„ í–‰ë ¬ì— ë¬´í•œê°’ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
                        
                        # ë³€ë™ì„± ê²€ì¦
                        vols = clean_returns.std()
                        if not np.isfinite(vols).all() or (vols == 0).any():
                            raise ValueError("ì¼ë¶€ ìì‚°ì˜ ë³€ë™ì„±ì´ 0ì´ê±°ë‚˜ ë¬´í•œê°’ì…ë‹ˆë‹¤.")
                        
                        # HRP ìµœì í™” ìˆ˜í–‰
                        hrp = HRPOpt(clean_returns)
                        raw_weights = hrp.optimize()
                        
                        # ê°€ì¤‘ì¹˜ ë³€í™˜ ë° ê²€ì¦
                        if isinstance(raw_weights, dict):
                            weights = {k: float(v) for k, v in raw_weights.items()}
                        else:
                            weights = {asset: float(w) for asset, w in zip(returns.columns, raw_weights)}
                        
                        # ê°€ì¤‘ì¹˜ ê²€ì¦
                        if not all(np.isfinite(list(weights.values()))):
                            raise ValueError("ìµœì í™”ëœ ê°€ì¤‘ì¹˜ì— ë¬´í•œê°’ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
                        
                        # ê°€ì¤‘ì¹˜ í•©ê³„ í™•ì¸ ë° ì •ê·œí™”
                        total_weight = sum(weights.values())
                        if not (0.99 <= total_weight <= 1.01):
                            weights = {k: v/total_weight for k, v in weights.items()}
                        
                        # í¬íŠ¸í´ë¦¬ì˜¤ ìˆ˜ìµë¥  ê³„ì‚°
                        weights_series = pd.Series(weights)
                        portfolio_returns = returns.dot(weights_series)
                        
                        # ì„±ê³¼ ì§€í‘œ ê³„ì‚°
                        annual_return = portfolio_returns.mean() * 252
                        annual_vol = portfolio_returns.std() * np.sqrt(252)
                        sharpe_ratio = annual_return / annual_vol if annual_vol != 0 else 0
                        
                        performance = (annual_return, annual_vol, sharpe_ratio)
                        
                        method_description = method_descriptions["ë¦¬ìŠ¤í¬ ê· í˜• (Risk Parity) âš–ï¸"]
                    except Exception as e:
                        st.error(f"Risk Parity Optimization Error: {str(e)}")
                        st.error("Troubleshooting:\n1. Increase analysis period (recommended min 1 year)\n"
                                 "2. Remove highly correlated assets\n"
                                 "3. Choose another optimization method")
                        # ìµœì í™” ì‹¤íŒ¨ ì‹œ í´ë°±(fallback) ì „ëµ
                        try:
                            cla = CLA(expected_returns.mean_historical_return(data), risk_models.sample_cov(data))
                            raw_weights = cla.max_sharpe()
                        except Exception as e:
                            st.warning("CLA Optimization failed, using alternative method...")
                            raw_weights = np.ones(len(expected_returns.mean_historical_return(data))) / len(expected_returns.mean_historical_return(data))
                        
                        # ê°€ì¤‘ì¹˜ í•©ê³„ í™•ì¸ ë° ì •ê·œí™”
                        total_weight = sum(raw_weights)
                        if not (0.99 <= total_weight <= 1.01):
                            raw_weights = {k: v/total_weight for k, v in raw_weights.items()}
                        
                        # í¬íŠ¸í´ë¦¬ì˜¤ ìˆ˜ìµë¥  ê³„ì‚°
                        weights_series = pd.Series(raw_weights)
                        portfolio_returns = returns.dot(weights_series)
                        
                        # ì„±ê³¼ ì§€í‘œ ê³„ì‚°
                        annual_return = portfolio_returns.mean() * 252
                        annual_vol = portfolio_returns.std() * np.sqrt(252)
                        sharpe_ratio = annual_return / annual_vol if annual_vol != 0 else 0
                        
                        performance = (annual_return, annual_vol, sharpe_ratio)
                
                # ê°€ì¤‘ì¹˜ ê²€ì¦ ë° í‘œì‹œ
                total_weight = sum(weights.values())
                if not (0.99 <= total_weight <= 1.01):
                    st.warning(
                        f"Portfolio weights sum is not equal to 1: {total_weight:.2f}"
                    )
                    weights = {k: v/total_weight for k, v in weights.items()}
            
                # ê²°ê³¼ í‘œì‹œ
                col1, col2 = st.columns(2)
                
                with col1:
                    st.subheader("Portfolio Composition")
                    weights_df = pd.DataFrame(
                        list(weights.items()),
                        columns=['Asset', 'Weight']
                    )
                    weights_df['Weight'] = weights_df['Weight'] * 100
                    
                    # ì›í˜• ì°¨íŠ¸ë¡œ í‘œì‹œ
                    fig_pie = plt.figure(figsize=(10, 6))
                    plt.pie(
                        weights_df['Weight'],
                        labels=weights_df['Asset'],
                        autopct='%1.1f%%',
                        startangle=90
                    )
                    plt.title("Portfolio Asset Allocation")
                    st.pyplot(fig_pie)
                    
                    # ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œë„ í‘œì‹œ
                    st.dataframe(weights_df.style.format({
                        'Weight': '{:.2f}%'
                    }))
            
                with col2:
                    st.subheader("Portfolio Performance Metrics")
                    metrics = {
                        'Annual Expected Return': performance[0],
                        'Annual Volatility': performance[1],
                        'Sharpe Ratio': performance[2]
                    }
                    metrics_df = pd.DataFrame(
                        metrics.items(),
                        columns=['Metric', 'Value']
                    )
                    st.dataframe(metrics_df.style.format({
                        'Value': '{:.2%}'
                    }))
                    
                    # ìœ„í—˜ ì§€í‘œ
                    portfolio_returns = returns.dot(list(weights.values()))
                    risk_metrics = calculate_risk_metrics(portfolio_returns)
                    risk_df = pd.DataFrame(
                        risk_metrics.items(),
                        columns=['Risk Metric', 'Value']
                    )
                    st.dataframe(risk_df.style.format({
                        'Value': '{:.4f}'
                    }))
                
                # ì „ëµ ì„¤ëª…
                st.markdown("### Selected Strategy Description")
                st.markdown(method_description)
                
                # ëˆ„ì  ìˆ˜ìµë¥  ë¹„êµ
                st.subheader("Comparison of Optimized Portfolio vs Individual Asset Returns")
                portfolio_cumulative = (1 + returns.dot(list(weights.values()))).cumprod()
                comparison_df = pd.concat([portfolio_cumulative, cumulative_returns], axis=1)
                comparison_df.columns = ['Optimized Portfolio'] + list(cumulative_returns.columns)
                st.line_chart(comparison_df)

            with tab2:
                st.header("ë¦¬ë°¸ëŸ°ì‹± ì‹œë®¬ë ˆì´ì…˜ ğŸ”„")
                
                # ì‚¬ì „ ì¡°ê±´ ê²€ì¦
                if 'weights' not in globals() or weights is None:
                    st.error("âš ï¸ ë¨¼ì € 'í¬íŠ¸í´ë¦¬ì˜¤ ìµœì í™”' íƒ­ì—ì„œ ë¶„ì„ì„ ì‹¤í–‰í•´ ì£¼ì„¸ìš”")
                    st.stop()
                
                initial_value = 10000  # USD ê¸°ì¤€
                
                # ë¦¬ë°¸ëŸ°ì‹± ì£¼ê¸° ë§¤í•‘
                freq_mapping = {
                    "Monthly": 'M',
                    "Quarterly": 'Q',
                    "Semi-Annually": '6M',
                    "Annually": 'A'
                }
                
                # ë¦¬ë°¸ëŸ°ì‹± ì‹œë®¬ë ˆì´ì…˜
                portfolio_value = initial_value
                dates = returns.index
                rebalance_dates = pd.date_range(
                    start=dates[0],
                    end=dates[-1],
                    freq=freq_mapping[rebalance_period]
                )
                
                portfolio_values = []
                current_weights = weights
                
                for date in dates:
                    if date in rebalance_dates:
                        # ë¦¬ë°¸ëŸ°ì‹± ìˆ˜í–‰
                        if optimization_method == "ìµœëŒ€ ìƒ¤í”„ ì§€ìˆ˜ (Maximum Sharpe Ratio) âš¡":
                            ef = EfficientFrontier(expected_returns.mean_historical_return(data), risk_models.sample_cov(data))
                            current_weights = ef.max_sharpe()
                            current_weights = ef.clean_weights()
                        elif optimization_method == "ìµœì†Œ ë³€ë™ì„± (Minimum Volatility) ğŸ›¡ï¸":
                            ef = EfficientFrontier(expected_returns.mean_historical_return(data), risk_models.sample_cov(data))
                            current_weights = ef.min_volatility()
                            current_weights = ef.clean_weights()
                        else:  # Risk Parity (Risk Parity)
                            hrp = HRPOpt(returns.loc[:date])
                            weights_array = hrp.optimize()
                            current_weights = {
                                asset: weight for asset, weight in 
                                zip(returns.columns, weights_array)
                            }
                    
                    # í¬íŠ¸í´ë¦¬ì˜¤ ê°€ì¹˜ ì—…ë°ì´íŠ¸
                    daily_return = returns.loc[date].dot(
                        list(current_weights.values())
                    )
                    portfolio_value *= (1 + daily_return)
                    portfolio_values.append(portfolio_value)
                
                # í¬íŠ¸í´ë¦¬ì˜¤ ê°€ì¹˜ ì‹œê³„ì—´ ìƒì„± (ë°ì´í„° íƒ€ì… ëª…ì‹œì  ë³€í™˜)
                portfolio_series = pd.Series(
                    data=np.array(portfolio_values, dtype=np.float64),  # ëª…ì‹œì  íƒ€ì… ì§€ì •
                    index=pd.to_datetime(dates),  # datetime ë³€í™˜ ë³´ì¥
                    name="Portfolio Value"
                )
                
                # ë¦¬ë°¸ëŸ°ì‹± ì •ë³´ í…Œì´ë¸” ìƒì„±
                rebalance_info = pd.DataFrame({
                    'Rebalancing Date': pd.to_datetime(rebalance_dates)
                })
                
                # í¬íŠ¸í´ë¦¬ì˜¤ ê°€ì¹˜ ì¶”ì¶œ ë°©ì‹ ê°œì„ 
                rebalance_info['Portfolio Value'] = rebalance_info['Rebalancing Date'].apply(
                    lambda x: portfolio_series.asof(x) if x >= portfolio_series.index[0] else np.nan
                ).dropna().astype(np.float64)
                
                # ê²°ê³¼ ì‹œê°í™”
                col1, col2 = st.columns(2)
                
                with col1:
                    st.subheader("Performance (USD)")
                    st.metric("Initial", f"${initial_value:,.2f}")
                    final_value = portfolio_series.iloc[-1]
                    total_return = (final_value - initial_value) / initial_value * 100
                    annual_return = (final_value / initial_value) ** (252/len(portfolio_series)) - 1
                    st.metric("Final Value", 
                            f"${final_value:,.2f}", 
                            f"{total_return:+.2f}%")
                
                with col2:
                    st.subheader("Portfolio Value")
                    st.line_chart(portfolio_series)
                
                # ë¦¬ë°¸ëŸ°ì‹± ì‹œì  í‘œì‹œ
                st.subheader("Rebalancing Information")
                
                col1, col2 = st.columns(2)
                
                with col1:
                    # í…Œì´ë¸” í˜•ì‹ìœ¼ë¡œ í‘œì‹œ
                    st.dataframe(rebalance_info.style.format({
                        'Portfolio Value': '${:,.2f}'
                    }))
                
                with col2:
                    # ë¦¬ë°¸ëŸ°ì‹± ì‹œì ì˜ í¬íŠ¸í´ë¦¬ì˜¤ ê°€ì¹˜ ë³€í™” ê·¸ë˜í”„
                    fig = plt.figure(figsize=(10, 6))
                    plt.plot(
                        rebalance_info['Rebalancing Date'].values.astype('datetime64[s]'),  # matplotlib í˜¸í™˜ í˜•ì‹
                        rebalance_info['Portfolio Value'].values.astype(np.float64),
                        marker='o', 
                        linestyle='-'
                    )
                    plt.title('Portfolio Value Change at Rebalancing Points')
                    plt.xticks(rotation=45)
                    plt.grid(True, linestyle='--', alpha=0.7)
                    plt.tight_layout()
                    st.pyplot(fig)
                    
                    # ë¦¬ë°¸ëŸ°ì‹± íš¨ê³¼ ì„¤ëª…
                    with st.expander("ğŸ“Š Rebalancing Effect Analysis", expanded=False):
                        # ë¦¬ë°¸ëŸ°ì‹± ì „í›„ ìˆ˜ìµë¥  ë³€í™” ê³„ì‚°
                        rebalance_returns = pd.Series(
                            index=rebalance_info.index[1:],
                            data=np.diff(rebalance_info['Portfolio Value']) / 
                                 rebalance_info['Portfolio Value'].iloc[:-1]
                        )
                        
                        st.markdown("""
                        ### Rebalancing Effect
                        - Portfolio weights are automatically adjusted at each rebalancing point.
                        - This results in automatic 'sell high, buy low' effect.
                        """)
                        
                        # ë¦¬ë°¸ëŸ°ì‹± êµ¬ê°„ë³„ ìˆ˜ìµë¥  í‘œì‹œ
                        st.markdown("#### Rebalancing Interval Returns")
                        returns_df = pd.DataFrame({
                            'Interval': [f"{start.strftime('%Y-%m-%d')} ~ {end.strftime('%Y-%m-%d')}"
                                    for start, end in zip(rebalance_info['Rebalancing Date'][:-1], 
                                                        rebalance_info['Rebalancing Date'][1:])],
                            'Interval Return': rebalance_returns
                        })
                        st.dataframe(returns_df.style.format({
                            'Interval Return': '{:.2%}'
                        }))

            with tab3:
                st.header("Stress Test")
                
                with st.expander("ğŸ“š What is Stress Test?", expanded=False):
                    st.markdown("""
                    ### What is Stress Test?
                    Stress Test is a method of simulating how a portfolio would react in various market crisis situations.
                    
                    ### Key Risk Metrics Description
                    | Metric | Description | Interpretation |
                    |------|------|------|
                    | **Volatility (Volatility)** | Degree of return change | Lower is better |
                    | **Sharpe (Sharpe Ratio)** | Return to risk ratio | Higher is better |
                    | **Sortino (Sortino Ratio)** | Return to downside risk | Higher is better |
                    | **MDD (Maximum Drawdown)** | Downside from peak to trough | Lower is better |
                    | **VaR (Value at Risk)** | Maximum expected loss at 95% confidence level | Lower is better |
                    | **CVaR (Conditional VaR)** | Average loss in case of VaR exceedance | Lower is better |
                    
                    ### Scenario Description
                    | Scenario | Shock | Description |
                    |----------|------|------|
                    | **Market Crash** | -20% | Sudden market collapse situation |
                    | **Severe Recession** | -30% | Severe economic downturn situation |
                    | **Moderate Downturn** | -10% | General market downturn situation |
                    | **Tech Bubble** | -25% | Tech bubble collapse situation |
                    | **Financial Crisis** | -35% | Financial crisis situation |
                    """)
                
                # ìŠ¤íŠ¸ë ˆìŠ¤ ì‹œë‚˜ë¦¬ì˜¤ ì •ì˜
                scenarios = {
                    "Market Crash": -0.20,
                    "Severe Recession": -0.30,
                    "Moderate Downturn": -0.10,
                    "Tech Bubble": -0.25,
                    "Financial Crisis": -0.35
                }
                
                # ìŠ¤íŠ¸ë ˆìŠ¤ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
                stress_results = run_stress_test(returns, scenarios)
                
                # ê²°ê³¼ ì‹œê°í™”
                stress_df = pd.DataFrame(stress_results).T
                st.dataframe(stress_df.style.format('{:.4f}'))
                
                # íˆíŠ¸ë§µ ìƒì„±
                fig, ax = plt.subplots(figsize=(10, 6))
                sns.heatmap(
                    stress_df, 
                    annot=True, 
                    fmt='.4f',
                    cmap='RdYlGn', 
                    center=0
                )
                st.pyplot(fig)
        
            with tab4:
                st.header("ë™ì  í—¤ì§€ ì „ëµ ğŸ›¡ï¸")
                
                # í—¤ì§€ íŒŒë¼ë¯¸í„° ì¤€ë¹„
                hedge_config = {
                    'base_threshold': base_threshold / 100,
                    'intensity': hedge_intensity,
                    'max_ratio': max_hedge_ratio
                }
                
                # ë°ì´í„° ì¤€ë¹„
                portfolio_returns, window_size = prepare_hedge_data(returns)
                
                # í—¤ì§€ ë¹„ìœ¨ ê³„ì‚°
                hedge_ratio = simulate_dynamic_hedge(
                    portfolio_returns,
                    window_size,
                    hedge_config
                )
                
                if hedge_ratio is not None:
                    # í—¤ì§€ ë¹„ìœ¨ ì‹œê³„ì—´ ìƒì„±
                    hedge_ratio_series = pd.Series(
                        hedge_ratio,
                        index=portfolio_returns.index[window_size:],
                        name='Hedge Ratio'
                    )
                    
                    # í—¤ì§€ ì ìš© ìˆ˜ìµë¥  ê³„ì‚°
                    hedged_returns = portfolio_returns[window_size:] * (1 - hedge_ratio_series)
                    
                    # ì‹œê°í™” ë¶€ë¶„ë§Œ ë³„ë„ í•¨ìˆ˜ë¡œ ë¶„ë¦¬
                    def update_hedge_visualization(hedge_ratio, hedged_returns):
                        """ì„ê³„ê°’ ë³€ê²½ ì‹œ ì‹œê°í™”ë§Œ ì—…ë°ì´íŠ¸"""
                        comparison = pd.DataFrame({
                            'ì›ë³¸ í¬íŠ¸í´ë¦¬ì˜¤': portfolio_returns[window_size:],
                            'í—¤ì§€ í¬íŠ¸í´ë¦¬ì˜¤': hedged_returns,
                            'í—¤ì§€ ë¹„ìœ¨': hedge_ratio
                        }).dropna()
                        
                        # ê²°ê³¼ ì‹œê°í™”
                        st.subheader("ìˆ˜ìµë¥  ë¹„êµ ğŸ“ˆ")
                        st.line_chart(comparison[['ì›ë³¸ í¬íŠ¸í´ë¦¬ì˜¤', 'í—¤ì§€ í¬íŠ¸í´ë¦¬ì˜¤']])
                        
                        # í—¤ì§€ ë¹„ìœ¨ ì°¨íŠ¸ ê°œì„ 
                        st.subheader("í—¤ì§€ ë¹„ìœ¨ ë³€í™” ì¶”ì´ ğŸ“‰")
                        
                        fig, ax = plt.subplots(figsize=(10, 4))
                        ax.fill_between(
                            comparison.index,
                            comparison['í—¤ì§€ ë¹„ìœ¨'],
                            color='red',
                            alpha=0.3,
                            label='í—¤ì§€ ë¹„ìœ¨'
                        )
                        ax.plot(
                            comparison.index,
                            comparison['í—¤ì§€ ë¹„ìœ¨'],
                            color='darkred',
                            linewidth=1.5
                        )
                        ax.set_ylim(0, 1.0)
                        ax.set_yticks(np.arange(0, 1.1, 0.2))
                        ax.set_ylabel('í—¤ì§€ ë¹„ìœ¨')
                        ax.legend(loc='upper left')
                        st.pyplot(fig)
                        
                        # í—¤ì§€ íš¨ê³¼ ë¶„ì„
                        col1, col2 = st.columns(2)
                        with col1:
                            st.subheader("ì›ë³¸ í¬íŠ¸í´ë¦¬ì˜¤ ì„±ê³¼ ì§€í‘œ")
                            original_metrics = calculate_risk_metrics(
                                portfolio_returns[window_size:]
                            )
                            metrics_df = pd.DataFrame(
                                original_metrics.items(),
                                columns=['Metric', 'Value']
                            )
                            st.dataframe(metrics_df.style.format({
                                'Value': '{:.4f}'
                            }))
                        
                        with col2:
                            st.subheader("í—¤ì§€ í¬íŠ¸í´ë¦¬ì˜¤ ì„±ê³¼ ì§€í‘œ")
                            hedged_metrics = calculate_risk_metrics(
                                hedged_returns
                            )
                            metrics_df = pd.DataFrame(
                                hedged_metrics.items(),
                                columns=['Metric', 'Value']
                            )
                            st.dataframe(metrics_df.style.format({
                                'Value': '{:.4f}'
                            }))
                    
                    update_hedge_visualization(hedge_ratio_series, hedged_returns)
                    
                    # í—¤ì§€ ì „ëµ ì„¤ëª… ì„¹ì…˜
                    with st.expander("ğŸ“š ë™ì  í—¤ì§€ ì „ëµ ìƒì„¸ ì„¤ëª…", expanded=True):
                        st.markdown(f"""
                        ### ğŸ› ï¸ í˜„ì¬ í—¤ì§€ ì„¤ì • ê°’
                        | íŒŒë¼ë¯¸í„° | ê°’ | ì„¤ëª… |
                        |----------|----|------|
                        | **ê¸°ë³¸ ë³€ë™ì„± ì„ê³„ê°’** | {base_threshold}% | í—¤ì§€ê°€ ì‹œì‘ë˜ëŠ” ë³€ë™ì„± ìˆ˜ì¤€ |
                        | **í—¤ì§€ ê°•ë„** | {hedge_intensity}x | ë³€ë™ì„± ì¦ê°€ì— ë”°ë¥¸ í—¤ì§€ ë°˜ì‘ ê°•ë„ |
                        | **ìµœëŒ€ í—¤ì§€ ë¹„ìœ¨** | {max_hedge_ratio*100}% | í¬íŠ¸í´ë¦¬ì˜¤ì˜ ìµœëŒ€ í—¤ì§€ ê°€ëŠ¥ ë¹„ì¤‘ |
                        
                        ### ğŸ“ˆ ì „ëµ ì‘ë™ ë©”ì»¤ë‹ˆì¦˜
                        1. **ì‹¤ì‹œê°„ ë³€ë™ì„± ì¶”ì **
                           - GARCH(1,1) ëª¨ë¸ì„ ì‚¬ìš©í•œ ë¡¤ë§ ìœˆë„ìš° ì˜ˆì¸¡ (3ê°œì›” ê¸°ì¤€)
                           - ì—°ìœ¨í™” ë³€ë™ì„±ìœ¼ë¡œ í™˜ì‚°í•˜ì—¬ ëª¨ë‹ˆí„°ë§
                        
                        2. **í—¤ì§€ ë¹„ìœ¨ ê²°ì •**
                           - ì˜ˆì¸¡ ë³€ë™ì„±ì´ ì„ê³„ê°’ ì´ˆê³¼ ì‹œ:  
                           `í—¤ì§€ ë¹„ìœ¨ = min(ìµœëŒ€í—¤ì§€ë¹„ìœ¨, (ì´ˆê³¼ë³€ë™ì„± / ê¸°ë³¸ì„ê³„ê°’) * í—¤ì§€ê°•ë„)`
                           - ì„ê³„ê°’ ë¯¸ë§Œ ì‹œ: í—¤ì§€ ë¹„ìœ¨ 0%
                        
                        3. **ë¦¬ìŠ¤í¬ ê´€ë¦¬**
                           - ì¼ì¼ í—¤ì§€ ë¹„ìœ¨ ì¬ê³„ì‚°
                           - ê¸‰ê²©í•œ ë³€ë™ì„± ì¦ê°€ ì‹œ ë‹¨ê³„ì  í—¤ì§€ ì¦ê°€
                           - ìµœëŒ€ í—¤ì§€ ë¹„ìœ¨ë¡œ ê³¼ë„í•œ í—¤ì§€ ë°©ì§€
                        
                        ### ğŸ’¡ íš¨ê³¼ì ì¸ ì‚¬ìš© ê°€ì´ë“œ
                        - **ë°©ì–´ì  ì „ëµ**: ë‚®ì€ ì„ê³„ê°’(10~15%) + ë†’ì€ ê°•ë„(1.5~2x)
                        - **ê· í˜• ì „ëµ**: ì¤‘ê°„ ì„ê³„ê°’(15~20%) + ê¸°ë³¸ ê°•ë„(1x)
                        - **ê³µê²©ì  ì „ëµ**: ë†’ì€ ì„ê³„ê°’(20%+) + ë‚®ì€ ê°•ë„(0.5~0.8x)
                        
                        ### âš ï¸ ì£¼ì˜ ì‚¬í•­
                        - ê³¼ë„í•œ í—¤ì§€ ê°•ë„ëŠ” ê¸°íšŒë¹„ìš© ì¦ê°€ë¡œ ì´ì–´ì§ˆ ìˆ˜ ìˆìŒ
                        - ë³€ë™ì„± ì˜ˆì¸¡ ëª¨ë¸ì˜ í•œê³„ ê³ ë ¤ (ê³¼ê±° ë°ì´í„° ê¸°ë°˜)
                        - ì‹¤ì œ ê±°ë˜ ì‹œ ì‹¤í–‰ ì‹œì°¨ ê³ ë ¤ í•„ìš”
                        """)
                else:
                    st.warning("í—¤ì§€ ë¶„ì„ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë³€ë™ì„± ì„ê³„ê°’ì„ ì¡°ì •í•´ ë³´ì„¸ìš”.")

        except Exception as e:
            st.error(f"ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
    else:
        st.error("ë°ì´í„° ë¡œë”© ì‹¤íŒ¨. ì¢…ëª© ì½”ë“œì™€ ê¸°ê°„ì„ í™•ì¸í•´ ì£¼ì„¸ìš”") 
